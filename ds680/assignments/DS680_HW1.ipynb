{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeet1912/ms/blob/main/ds680/assignments/DS680_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN0hWV8Xe4gW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyRdAmw-e4gZ",
        "outputId": "e95cd554-9ef6-40e7-da9b-fdb64ee37d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens:  189\n",
            "Number of sentences:  8\n",
            "Number of tokens in sentence tokenizer:  189\n"
          ]
        }
      ],
      "source": [
        "excerpt = \"In the next couple of decades, we will be able to do things that would have seemed like magic to our grandparents. This phenomenon is not new, but it will be newly accelerated. People have become dramatically more capable over time; we can already accomplish things now that our predecessors would have believed to be impossible. We are more capable not because of genetic change, but because we benefit from the infrastructure of society being way smarter and more capable than any one of us; in an important sense, society itself is a form of advanced intelligence. Our grandparents – and the generations that came before them – built and achieved great things. They contributed to the scaffolding of human progress that we all benefit from. AI will give people tools to solve hard problems and help us add new struts to that scaffolding that we couldn’t have figured out on our own. The story of progress will continue, and our children will be able to do things we can’t.\"\n",
        "\n",
        "tokens = nltk.word_tokenize(excerpt)\n",
        "sentences = nltk.sent_tokenize(excerpt)\n",
        "\n",
        "numberOftokens = 0\n",
        "numberOfSentences = 0\n",
        "\n",
        "for word in tokens:\n",
        "    numberOftokens += 1\n",
        "\n",
        "for sentence in sentences:\n",
        "    numberOfSentences += 1\n",
        "\n",
        "numberOftokensInSentenceTokenizer = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "    tokensInSentence = nltk.word_tokenize(sentence)\n",
        "    for word in tokensInSentence:\n",
        "        numberOftokensInSentenceTokenizer += 1\n",
        "\n",
        "print(\"Number of tokens: \", numberOftokens)\n",
        "print(\"Number of sentences: \", numberOfSentences)\n",
        "print(\"Number of tokens in sentence tokenizer: \", numberOftokensInSentenceTokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOwc0u7Ee4ga",
        "outputId": "9b618227-4389-4574-9397-176aa242e04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['In', 'the', 'next', 'couple', 'of', 'decades', ',', 'we', 'will', 'be', 'able', 'to', 'do', 'things', 'that', 'would', 'have', 'seemed', 'like', 'magic', 'to', 'our', 'grandparents', '.', 'This', 'phenomenon', 'is', 'not', 'new', ',', 'but', 'it', 'will', 'be', 'newly', 'accelerated', '.', 'People', 'have', 'become', 'dramatically', 'more', 'capable', 'over', 'time', ';', 'we', 'can', 'already', 'accomplish', 'things', 'now', 'that', 'our', 'predecessors', 'would', 'have', 'believed', 'to', 'be', 'impossible', '.', 'We', 'are', 'more', 'capable', 'not', 'because', 'of', 'genetic', 'change', ',', 'but', 'because', 'we', 'benefit', 'from', 'the', 'infrastructure', 'of', 'society', 'being', 'way', 'smarter', 'and', 'more', 'capable', 'than', 'any', 'one', 'of', 'us', ';', 'in', 'an', 'important', 'sense', ',', 'society', 'itself', 'is', 'a', 'form', 'of', 'advanced', 'intelligence', '.', 'Our', 'grandparents', '–', 'and', 'the', 'generations', 'that', 'came', 'before', 'them', '–', 'built', 'and', 'achieved', 'great', 'things', '.', 'They', 'contributed', 'to', 'the', 'scaffolding', 'of', 'human', 'progress', 'that', 'we', 'all', 'benefit', 'from', '.', 'AI', 'will', 'give', 'people', 'tools', 'to', 'solve', 'hard', 'problems', 'and', 'help', 'us', 'add', 'new', 'struts', 'to', 'that', 'scaffolding', 'that', 'we', 'couldn', '’', 't', 'have', 'figured', 'out', 'on', 'our', 'own', '.', 'The', 'story', 'of', 'progress', 'will', 'continue', ',', 'and', 'our', 'children', 'will', 'be', 'able', 'to', 'do', 'things', 'we', 'can', '’', 't', '.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M56KJNCe4ga",
        "outputId": "82d8f796-cc0f-4528-b3fe-6f6243e1c158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Tokens:  ['In the next couple of decades, we will be able to do things that would have seemed like magic to our grandparents.', 'This phenomenon is not new, but it will be newly accelerated.', 'People have become dramatically more capable over time; we can already accomplish things now that our predecessors would have believed to be impossible.', 'We are more capable not because of genetic change, but because we benefit from the infrastructure of society being way smarter and more capable than any one of us; in an important sense, society itself is a form of advanced intelligence.', 'Our grandparents – and the generations that came before them – built and achieved great things.', 'They contributed to the scaffolding of human progress that we all benefit from.', 'AI will give people tools to solve hard problems and help us add new struts to that scaffolding that we couldn’t have figured out on our own.', 'The story of progress will continue, and our children will be able to do things we can’t.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Sentence Tokens: \", sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17sK1Kspe4ga",
        "outputId": "895c99d2-becb-4952-ca21-65b004f12c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens after stemming with  ORIGINAL_ALGORITHM : 189\n",
            "Number of tokens after stemming with  MARTIN_EXTENSIONS : 189\n",
            "Number of tokens after stemming with  NLTK_EXTENSIONS : 189\n"
          ]
        }
      ],
      "source": [
        "lowerCaseTokens = [token.lower() for token in tokens] # list comprehension\n",
        "stemmedTokensDict = {}\n",
        "\n",
        "for algo in [\"ORIGINAL_ALGORITHM\", \"MARTIN_EXTENSIONS\",\"NLTK_EXTENSIONS\"]:\n",
        "    stemmer = nltk.PorterStemmer(mode=algo)\n",
        "    stemmedTokens = [stemmer.stem(token) for token in lowerCaseTokens]\n",
        "    stemmedTokensDict[algo] = stemmedTokens\n",
        "\n",
        "for algo, tokens in stemmedTokensDict.items():\n",
        "    numberOftokens = 0\n",
        "    for token in tokens:\n",
        "        numberOftokens += 1\n",
        "    print(\"Number of tokens after stemming with \", algo, \":\", numberOftokens)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45GzyMzUe4gb"
      },
      "source": [
        "Moving on with the default implementation, i.e, NLTK_EXTENSIONS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzuk_rh1e4gb",
        "outputId": "3f514b2c-48d0-4c23-b95c-a50347260914"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['in',\n",
              " 'the',\n",
              " 'next',\n",
              " 'coupl',\n",
              " 'of',\n",
              " 'decad',\n",
              " ',',\n",
              " 'we',\n",
              " 'will',\n",
              " 'be',\n",
              " 'abl',\n",
              " 'to',\n",
              " 'do',\n",
              " 'thing',\n",
              " 'that',\n",
              " 'would',\n",
              " 'have',\n",
              " 'seem',\n",
              " 'like',\n",
              " 'magic',\n",
              " 'to',\n",
              " 'our',\n",
              " 'grandpar',\n",
              " '.',\n",
              " 'thi',\n",
              " 'phenomenon',\n",
              " 'is',\n",
              " 'not',\n",
              " 'new',\n",
              " ',',\n",
              " 'but',\n",
              " 'it',\n",
              " 'will',\n",
              " 'be',\n",
              " 'newli',\n",
              " 'acceler',\n",
              " '.',\n",
              " 'peopl',\n",
              " 'have',\n",
              " 'becom',\n",
              " 'dramat',\n",
              " 'more',\n",
              " 'capabl',\n",
              " 'over',\n",
              " 'time',\n",
              " ';',\n",
              " 'we',\n",
              " 'can',\n",
              " 'alreadi',\n",
              " 'accomplish',\n",
              " 'thing',\n",
              " 'now',\n",
              " 'that',\n",
              " 'our',\n",
              " 'predecessor',\n",
              " 'would',\n",
              " 'have',\n",
              " 'believ',\n",
              " 'to',\n",
              " 'be',\n",
              " 'imposs',\n",
              " '.',\n",
              " 'we',\n",
              " 'are',\n",
              " 'more',\n",
              " 'capabl',\n",
              " 'not',\n",
              " 'becaus',\n",
              " 'of',\n",
              " 'genet',\n",
              " 'chang',\n",
              " ',',\n",
              " 'but',\n",
              " 'becaus',\n",
              " 'we',\n",
              " 'benefit',\n",
              " 'from',\n",
              " 'the',\n",
              " 'infrastructur',\n",
              " 'of',\n",
              " 'societi',\n",
              " 'be',\n",
              " 'way',\n",
              " 'smarter',\n",
              " 'and',\n",
              " 'more',\n",
              " 'capabl',\n",
              " 'than',\n",
              " 'ani',\n",
              " 'one',\n",
              " 'of',\n",
              " 'us',\n",
              " ';',\n",
              " 'in',\n",
              " 'an',\n",
              " 'import',\n",
              " 'sens',\n",
              " ',',\n",
              " 'societi',\n",
              " 'itself',\n",
              " 'is',\n",
              " 'a',\n",
              " 'form',\n",
              " 'of',\n",
              " 'advanc',\n",
              " 'intellig',\n",
              " '.',\n",
              " 'our',\n",
              " 'grandpar',\n",
              " '–',\n",
              " 'and',\n",
              " 'the',\n",
              " 'gener',\n",
              " 'that',\n",
              " 'came',\n",
              " 'befor',\n",
              " 'them',\n",
              " '–',\n",
              " 'built',\n",
              " 'and',\n",
              " 'achiev',\n",
              " 'great',\n",
              " 'thing',\n",
              " '.',\n",
              " 'they',\n",
              " 'contribut',\n",
              " 'to',\n",
              " 'the',\n",
              " 'scaffold',\n",
              " 'of',\n",
              " 'human',\n",
              " 'progress',\n",
              " 'that',\n",
              " 'we',\n",
              " 'all',\n",
              " 'benefit',\n",
              " 'from',\n",
              " '.',\n",
              " 'ai',\n",
              " 'will',\n",
              " 'give',\n",
              " 'peopl',\n",
              " 'tool',\n",
              " 'to',\n",
              " 'solv',\n",
              " 'hard',\n",
              " 'problem',\n",
              " 'and',\n",
              " 'help',\n",
              " 'us',\n",
              " 'add',\n",
              " 'new',\n",
              " 'strut',\n",
              " 'to',\n",
              " 'that',\n",
              " 'scaffold',\n",
              " 'that',\n",
              " 'we',\n",
              " 'couldn',\n",
              " '’',\n",
              " 't',\n",
              " 'have',\n",
              " 'figur',\n",
              " 'out',\n",
              " 'on',\n",
              " 'our',\n",
              " 'own',\n",
              " '.',\n",
              " 'the',\n",
              " 'stori',\n",
              " 'of',\n",
              " 'progress',\n",
              " 'will',\n",
              " 'continu',\n",
              " ',',\n",
              " 'and',\n",
              " 'our',\n",
              " 'children',\n",
              " 'will',\n",
              " 'be',\n",
              " 'abl',\n",
              " 'to',\n",
              " 'do',\n",
              " 'thing',\n",
              " 'we',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " '.']"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemmedTokensDict[\"NLTK_EXTENSIONS\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t982MN0Ee4gc",
        "outputId": "bc9c8a57-d7d7-4e0d-cba6-cfa6c968006d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS tags:  [('In', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('couple', 'NN'), ('of', 'IN'), ('decades', 'NNS'), (',', ','), ('we', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('things', 'NNS'), ('that', 'WDT'), ('would', 'MD'), ('have', 'VB'), ('seemed', 'VBN'), ('like', 'IN'), ('magic', 'NN'), ('to', 'TO'), ('our', 'PRP$'), ('grandparents', 'NNS'), ('.', '.'), ('This', 'DT'), ('phenomenon', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('new', 'JJ'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('newly', 'RB'), ('accelerated', 'VBN'), ('.', '.'), ('People', 'NNS'), ('have', 'VBP'), ('become', 'VBN'), ('dramatically', 'RB'), ('more', 'RBR'), ('capable', 'JJ'), ('over', 'IN'), ('time', 'NN'), (';', ':'), ('we', 'PRP'), ('can', 'MD'), ('already', 'RB'), ('accomplish', 'VB'), ('things', 'NNS'), ('now', 'RB'), ('that', 'IN'), ('our', 'PRP$'), ('predecessors', 'NNS'), ('would', 'MD'), ('have', 'VB'), ('believed', 'VBN'), ('to', 'TO'), ('be', 'VB'), ('impossible', 'JJ'), ('.', '.'), ('We', 'PRP'), ('are', 'VBP'), ('more', 'RBR'), ('capable', 'JJ'), ('not', 'RB'), ('because', 'IN'), ('of', 'IN'), ('genetic', 'JJ'), ('change', 'NN'), (',', ','), ('but', 'CC'), ('because', 'IN'), ('we', 'PRP'), ('benefit', 'VBP'), ('from', 'IN'), ('the', 'DT'), ('infrastructure', 'NN'), ('of', 'IN'), ('society', 'NN'), ('being', 'VBG'), ('way', 'NN'), ('smarter', 'NN'), ('and', 'CC'), ('more', 'RBR'), ('capable', 'JJ'), ('than', 'IN'), ('any', 'DT'), ('one', 'CD'), ('of', 'IN'), ('us', 'PRP'), (';', ':'), ('in', 'IN'), ('an', 'DT'), ('important', 'JJ'), ('sense', 'NN'), (',', ','), ('society', 'NN'), ('itself', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('form', 'NN'), ('of', 'IN'), ('advanced', 'JJ'), ('intelligence', 'NN'), ('.', '.'), ('Our', 'PRP$'), ('grandparents', 'NNS'), ('–', 'NN'), ('and', 'CC'), ('the', 'DT'), ('generations', 'NNS'), ('that', 'WDT'), ('came', 'VBD'), ('before', 'IN'), ('them', 'PRP'), ('–', 'VBP'), ('built', 'VBN'), ('and', 'CC'), ('achieved', 'VBN'), ('great', 'JJ'), ('things', 'NNS'), ('.', '.'), ('They', 'PRP'), ('contributed', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('scaffolding', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('progress', 'NN'), ('that', 'IN'), ('we', 'PRP'), ('all', 'DT'), ('benefit', 'VBP'), ('from', 'IN'), ('.', '.'), ('AI', 'NNP'), ('will', 'MD'), ('give', 'VB'), ('people', 'NNS'), ('tools', 'NNS'), ('to', 'TO'), ('solve', 'VB'), ('hard', 'JJ'), ('problems', 'NNS'), ('and', 'CC'), ('help', 'VB'), ('us', 'PRP'), ('add', 'VB'), ('new', 'JJ'), ('struts', 'NNS'), ('to', 'TO'), ('that', 'DT'), ('scaffolding', 'VBG'), ('that', 'IN'), ('we', 'PRP'), ('couldn', 'VBP'), ('’', 'JJ'), ('t', 'NNS'), ('have', 'VBP'), ('figured', 'VBN'), ('out', 'RP'), ('on', 'IN'), ('our', 'PRP$'), ('own', 'JJ'), ('.', '.'), ('The', 'DT'), ('story', 'NN'), ('of', 'IN'), ('progress', 'NN'), ('will', 'MD'), ('continue', 'VB'), (',', ','), ('and', 'CC'), ('our', 'PRP$'), ('children', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('things', 'NNS'), ('we', 'PRP'), ('can', 'MD'), ('’', 'VB'), ('t', 'NN'), ('.', '.')]\n",
            "POS tags counter:  defaultdict(<class 'int'>, {'IN': 21, 'DT': 11, 'JJ': 17, 'NN': 19, 'NNS': 16, ',': 5, 'PRP': 13, 'MD': 9, 'VB': 15, 'TO': 7, 'WDT': 2, 'VBN': 7, 'PRP$': 5, '.': 8, 'VBZ': 2, 'RB': 6, 'CC': 7, 'VBP': 7, 'RBR': 3, ':': 2, 'VBG': 2, 'CD': 1, 'VBD': 2, 'NNP': 1, 'RP': 1})\n"
          ]
        }
      ],
      "source": [
        "posTags = nltk.pos_tag(tokens)\n",
        "print(\"POS tags: \", posTags)\n",
        "pos_tag_counts = defaultdict(int)\n",
        "for word, tag in posTags:\n",
        "    pos_tag_counts[tag] += 1\n",
        "\n",
        "print(\"POS tags counter: \", pos_tag_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMTdGXNXe4gc",
        "outputId": "3e5f9e4a-e9b7-4c76-b9d2-5aa248db1f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('more', 'capable'),\n",
              " ('will', 'be'),\n",
              " (',', 'but'),\n",
              " ('able', 'to'),\n",
              " ('be', 'able'),\n",
              " ('benefit', 'from'),\n",
              " ('do', 'things'),\n",
              " ('that', 'we'),\n",
              " ('to', 'do'),\n",
              " ('we', 'can'),\n",
              " ('would', 'have'),\n",
              " ('’', 't'),\n",
              " (',', 'and'),\n",
              " (',', 'society'),\n",
              " (',', 'we'),\n",
              " ('.', 'AI')]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.collocations.BigramCollocationFinder.from_words(tokens).nbest(nltk.collocations.BigramAssocMeasures().raw_freq,16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KpClf6Qe4gc",
        "outputId": "3142a424-6f02-4447-cbf4-ab7d2d14e377"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('able', 'to', 'do'),\n",
              " ('be', 'able', 'to'),\n",
              " ('to', 'do', 'things'),\n",
              " ('will', 'be', 'able'),\n",
              " (',', 'and', 'our'),\n",
              " (',', 'but', 'because'),\n",
              " (',', 'but', 'it'),\n",
              " (',', 'society', 'itself'),\n",
              " (',', 'we', 'will'),\n",
              " ('.', 'AI', 'will'),\n",
              " ('.', 'Our', 'grandparents'),\n",
              " ('.', 'People', 'have'),\n",
              " ('.', 'The', 'story'),\n",
              " ('.', 'They', 'contributed'),\n",
              " ('.', 'This', 'phenomenon'),\n",
              " ('.', 'We', 'are')]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.collocations.TrigramCollocationFinder.from_words(tokens).nbest(nltk.collocations.TrigramAssocMeasures().raw_freq,16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icl2Z5wfe4gc",
        "outputId": "53f00890-a5e9-441b-9c33-f80abc490ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered bigrams:\n",
            "('will', 'be') 3\n",
            "('be', 'able') 2\n",
            "('able', 'to') 2\n",
            "('to', 'do') 2\n",
            "('do', 'things') 2\n",
            "('would', 'have') 2\n",
            "(',', 'but') 2\n",
            "('more', 'capable') 3\n",
            "('we', 'can') 2\n",
            "('benefit', 'from') 2\n",
            "('that', 'we') 2\n",
            "('’', 't') 2\n",
            "\n",
            "Filtered trigrams:\n",
            "('will', 'be', 'able') 2\n",
            "('be', 'able', 'to') 2\n",
            "('able', 'to', 'do') 2\n",
            "('to', 'do', 'things') 2\n"
          ]
        }
      ],
      "source": [
        "bigrams = ngrams(tokens, 2)\n",
        "trigrams = ngrams(tokens, 3)\n",
        "\n",
        "def filter_ngrams(ngrams, min_count=2):\n",
        "  filtered_ngrams = [(ngram,count) for ngram, count in Counter(ngrams).items() if count >= min_count]\n",
        "  return filtered_ngrams\n",
        "\n",
        "filtered_bigrams = filter_ngrams(bigrams)\n",
        "filtered_trigrams = filter_ngrams(trigrams)\n",
        "\n",
        "print(\"Filtered bigrams:\")\n",
        "for bigram, count in filtered_bigrams:\n",
        "  print(bigram, count)\n",
        "\n",
        "print(\"\\nFiltered trigrams:\")\n",
        "for trigram, count in filtered_trigrams:\n",
        "  print(trigram, count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KaTOtK8e4gc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}