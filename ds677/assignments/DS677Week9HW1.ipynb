{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeet1912/ms/blob/main/ds677/assignments/DS677Week9HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### My kaggle id: abhijeetsahdev"
      ],
      "metadata": {
        "id": "GAY_33I7dUuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jomDFvWMpfe",
        "outputId": "19c52c26-cb71-4a3a-e66a-7f2184c00c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "CWP2TbpOY-Vx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z89ASd-XSkIQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(33)\n",
        "tf.random.set_seed(33)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on CPU/GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3-TrK4M1Rhd",
        "outputId": "280aa099-7c85-4dfe-914e-0c4b97481bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "5ksJ_TjWZsHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadhdf5Data(file_path):\n",
        "  with h5py.File(file_path, 'r') as hdf:\n",
        "    H_Re = tf.convert_to_tensor(hdf['H_Re'][:], dtype=tf.float32)\n",
        "    H_Im = tf.convert_to_tensor(hdf['H_Im'][:], dtype=tf.float32)\n",
        "    SNR = tf.convert_to_tensor(hdf['SNR'][:], dtype=tf.float32)\n",
        "    if 'Pos' in hdf:\n",
        "      Pos = tf.convert_to_tensor(hdf['Pos'][:], dtype=tf.float32)\n",
        "      return tf.concat([H_Re, H_Im], axis=-1), SNR, Pos\n",
        "    return tf.concat([H_Re, H_Im], axis=-1), SNR, tf.zeros((1, 3))  # Placeholder if no Pos data\n",
        "\n",
        "def preprocess(file_path, use_tpu=False):\n",
        "  if use_tpu:\n",
        "    with strategy.scope():\n",
        "      return loadhdf5Data(file_path)\n",
        "  else:\n",
        "      return loadhdf5Data(file_path)"
      ],
      "metadata": {
        "id": "OjOnU-YG112Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelledPath = \"/content/drive/MyDrive/ds677/week9/labelled_data/\"\n",
        "labelled_data = []\n",
        "with strategy.scope():\n",
        "  for i in range(1, 9):\n",
        "    file_path = f\"{labelledPath}file_{i}.hdf5\"\n",
        "    data, snr, pos = preprocess(file_path, use_tpu=False)\n",
        "    labelled_data.append((data, snr, pos))\n",
        "\n",
        "    # Concatenate data\n",
        "    H_labelled, SNR_labelled, Pos_labelled = zip(*labelled_data)\n",
        "    H_labelled = tf.concat(H_labelled, axis=0)\n",
        "    SNR_labelled = tf.concat(SNR_labelled, axis=0)\n",
        "    Pos_labelled = tf.concat(Pos_labelled, axis=0)\n",
        "\n",
        "    H_labelled_np = H_labelled.numpy()\n",
        "    Pos_labelled_np = Pos_labelled.numpy()\n",
        "\n",
        "    # Split labelled data into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(H_labelled_np, Pos_labelled_np, test_size=0.3, random_state=33)\n",
        "\n",
        "    X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "    X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "    y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "    y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "\n",
        "# Unlabelled data\n",
        "unlabelled_path = \"/content/drive/MyDrive/ds677/week9/unlabelled_data/\"\n",
        "unlabelled_data = []\n",
        "with strategy.scope():\n",
        "  for i in range(1, 65):\n",
        "    file_path = f\"{unlabelled_path}file_{i}.hdf5\"\n",
        "    data, snr, _ = preprocess(file_path, use_tpu=True)\n",
        "    unlabelled_data.append((data, snr))\n",
        "\n",
        "  H_unlabelled, SNR_unlabelled = zip(*unlabelled_data)\n",
        "  H_unlabelled = tf.concat(H_unlabelled, axis=0)\n"
      ],
      "metadata": {
        "id": "__4lWb-zZInf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would be an act of tremendous/unparalleled/unprecedented generosity if we could store processed outputs at each stage of a DL pipeline."
      ],
      "metadata": {
        "id": "Wzclxky29N7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Supervised Model"
      ],
      "metadata": {
        "id": "DqG4DJ-8aoVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  def buildSelfSupervisedModel(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(np.prod(input_shape), activation='linear'),\n",
        "        layers.Reshape(input_shape)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "  # changed LR to 0.0008 from 0.0005\n",
        "  lr = 0.0008\n",
        "  optimizer = Adam(learning_rate=lr)\n",
        "  loss = 'mse'\n",
        "\n",
        "  self_supervised_model = buildSelfSupervisedModel(H_unlabelled.shape[1:])\n",
        "  self_supervised_model.compile(optimizer=optimizer, loss=loss)\n",
        "  self_supervised_model.fit(H_unlabelled, H_unlabelled, epochs=50, batch_size=128*8, validation_split=0.13)"
      ],
      "metadata": {
        "id": "FHacbaINaJCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2708d8-59e0-4fba-cd81-9d02aefb7689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 204s 5s/step - loss: 0.0403 - val_loss: 0.0238\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0277 - val_loss: 0.0188\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0220 - val_loss: 0.0151\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 119s 4s/step - loss: 0.0176 - val_loss: 0.0132\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0155 - val_loss: 0.0121\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0143 - val_loss: 0.0111\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0135 - val_loss: 0.0105\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0127 - val_loss: 0.0101\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 127s 4s/step - loss: 0.0122 - val_loss: 0.0099\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0117 - val_loss: 0.0094\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0112 - val_loss: 0.0092\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0109 - val_loss: 0.0090\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0106 - val_loss: 0.0088\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0104 - val_loss: 0.0087\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0102 - val_loss: 0.0085\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0101 - val_loss: 0.0087\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0100 - val_loss: 0.0084\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0099 - val_loss: 0.0083\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0097 - val_loss: 0.0082\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0096 - val_loss: 0.0082\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 124s 4s/step - loss: 0.0095 - val_loss: 0.0080\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0094 - val_loss: 0.0080\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0093 - val_loss: 0.0079\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 119s 4s/step - loss: 0.0092 - val_loss: 0.0078\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 119s 4s/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0091 - val_loss: 0.0078\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0090 - val_loss: 0.0077\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0089 - val_loss: 0.0076\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0090 - val_loss: 0.0076\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0088 - val_loss: 0.0076\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 124s 4s/step - loss: 0.0088 - val_loss: 0.0075\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0088 - val_loss: 0.0076\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0088 - val_loss: 0.0075\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0087 - val_loss: 0.0075\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0087 - val_loss: 0.0074\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0086 - val_loss: 0.0074\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0086 - val_loss: 0.0075\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0085 - val_loss: 0.0074\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0085 - val_loss: 0.0074\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0083 - val_loss: 0.0074\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0083 - val_loss: 0.0072\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 124s 4s/step - loss: 0.0082 - val_loss: 0.0072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wish we could plot loss and val_loss right here and append the System Ram and Disk plots from Resources. The above image was obtained with |validation set| = 0.1 * H_unlabeled.\n",
        "// unlabelled or labeled.  ![Screenshot 2024-11-12 at 07.17.43.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "PmVchqBkTc25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supervised Model"
      ],
      "metadata": {
        "id": "ynCzV8CtawuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  def buildSupervisedModel(input_shape, output_shape):\n",
        "      base_model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu')\n",
        "      ])\n",
        "\n",
        "      model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(output_shape)\n",
        "    ])\n",
        "      return model\n",
        "\n",
        "  # Extracting features from self-supervised model\n",
        "  features = self_supervised_model.predict(X_train)\n",
        "\n",
        "  lr = 0.0008\n",
        "  optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "  supervised_model = buildSupervisedModel(features.shape[1:], y_train.shape[1])\n",
        "  supervised_model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "  # Training the supervised model\n",
        "  history = supervised_model.fit(features, y_train, validation_data=(self_supervised_model.predict(X_val), y_val), epochs=1000, batch_size=128*8)"
      ],
      "metadata": {
        "id": "p4asHR7fawZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c7788a-97a3-4541-c3dc-c3d92b625241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 119s 587ms/step\n",
            "39/39 [==============================] - 33s 862ms/step\n",
            "Epoch 1/1000\n",
            "3/3 [==============================] - 50s 16s/step - loss: 130903.4375 - val_loss: 121850.1562\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 113769.3516 - val_loss: 104990.6406\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 102824.8516 - val_loss: 99644.0625\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 94954.0781 - val_loss: 90841.0703\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 87141.0703 - val_loss: 82778.1172\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 77896.0391 - val_loss: 72144.6250\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 68479.3281 - val_loss: 62023.3672\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 57380.2539 - val_loss: 49959.4688\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 45661.8008 - val_loss: 38058.4492\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 34180.7695 - val_loss: 28842.0039\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 27385.6855 - val_loss: 26959.3164\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 26929.8164 - val_loss: 28939.6328\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 28577.5176 - val_loss: 28369.0449\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 27085.9844 - val_loss: 25838.8105\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 24803.2949 - val_loss: 24833.2148\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 24412.5391 - val_loss: 25485.8047\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 24794.7871 - val_loss: 25009.9297\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 24062.1367 - val_loss: 24143.5156\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 23370.9375 - val_loss: 23779.6543\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 23138.0645 - val_loss: 23768.9219\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 23112.3398 - val_loss: 23700.5664\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 22944.4375 - val_loss: 23433.2832\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 22673.9785 - val_loss: 23139.3711\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 22448.5508 - val_loss: 22983.9414\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 22298.0000 - val_loss: 22813.6250\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 22117.0176 - val_loss: 22606.2969\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 21915.8047 - val_loss: 22421.1504\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 21731.4648 - val_loss: 22289.1270\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 21565.4668 - val_loss: 22057.0020\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 21368.3477 - val_loss: 21834.5508\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 21156.2852 - val_loss: 21655.1055\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 20959.8301 - val_loss: 21421.1934\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 20734.7695 - val_loss: 21185.7676\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 20500.2559 - val_loss: 20916.0820\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 20290.5137 - val_loss: 20639.5371\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 19996.2539 - val_loss: 20419.6152\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 19774.3203 - val_loss: 20047.3125\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 19528.4707 - val_loss: 19736.9043\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 19145.8496 - val_loss: 19565.7422\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 18909.0527 - val_loss: 19048.8438\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 18611.0312 - val_loss: 18725.5137\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 18237.2324 - val_loss: 18399.3398\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 17927.6484 - val_loss: 17965.6309\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 17559.5000 - val_loss: 17687.3848\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 17200.8711 - val_loss: 17220.1660\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 16897.0039 - val_loss: 16947.9902\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 16576.0352 - val_loss: 16482.7363\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 16236.8398 - val_loss: 16156.4424\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 15935.5156 - val_loss: 15864.9404\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 15644.4941 - val_loss: 15486.0459\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 15393.7402 - val_loss: 15270.9600\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 15221.1758 - val_loss: 14955.9170\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 14897.2422 - val_loss: 14834.8428\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 14683.5381 - val_loss: 14483.4072\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 14423.2910 - val_loss: 14336.7451\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 14125.4717 - val_loss: 14007.2256\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 13963.6611 - val_loss: 13766.3418\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 13767.1475 - val_loss: 13721.0645\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 13452.7607 - val_loss: 13329.2090\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 13200.9434 - val_loss: 13183.6016\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 13048.2041 - val_loss: 12999.6416\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 12877.5527 - val_loss: 12800.4170\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 12711.3125 - val_loss: 12730.2510\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 12523.6328 - val_loss: 12464.9443\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 12367.0723 - val_loss: 12369.0361\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 12235.3320 - val_loss: 12219.1699\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 11977.1914 - val_loss: 12005.4502\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 11799.3457 - val_loss: 11872.1436\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 11655.0947 - val_loss: 11762.1543\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 11529.9990 - val_loss: 11762.2197\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 11445.0811 - val_loss: 11636.5078\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 11403.7295 - val_loss: 11422.2402\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 11129.1777 - val_loss: 11369.9287\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 11150.1895 - val_loss: 11391.6729\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 11025.4580 - val_loss: 11108.5469\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10960.6641 - val_loss: 11080.9404\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10715.5371 - val_loss: 11142.6641\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10647.3691 - val_loss: 11268.1631\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10601.7998 - val_loss: 10924.0176\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10434.0381 - val_loss: 10698.3857\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10305.1016 - val_loss: 10432.7432\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10438.1357 - val_loss: 10487.7070\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10321.9980 - val_loss: 10867.5703\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10207.3193 - val_loss: 10509.1924\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 10255.4492 - val_loss: 10170.0029\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9953.2891 - val_loss: 10025.9307\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9810.3340 - val_loss: 10005.6611\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9734.6768 - val_loss: 10064.4941\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9668.3838 - val_loss: 9959.0557\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9622.0488 - val_loss: 9694.0566\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 9s 3s/step - loss: 9424.4814 - val_loss: 9620.7236\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9352.8896 - val_loss: 9631.6240\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9299.9365 - val_loss: 9788.7314\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 9322.5381 - val_loss: 9757.8906\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 9382.5537 - val_loss: 9522.6953\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9402.6689 - val_loss: 9514.9854\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9314.2480 - val_loss: 9381.0879\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9120.4277 - val_loss: 9850.9238\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9366.8701 - val_loss: 9319.8916\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 9081.1367 - val_loss: 9046.7891\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8900.2842 - val_loss: 9167.6836\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8884.6934 - val_loss: 9082.4492\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8834.0137 - val_loss: 8971.1748\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8677.4150 - val_loss: 8839.8027\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8698.2949 - val_loss: 8961.4824\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8681.0996 - val_loss: 9232.9102\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8864.9609 - val_loss: 9273.6123\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8801.5957 - val_loss: 8968.7939\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8592.3896 - val_loss: 8640.6377\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8459.3135 - val_loss: 8655.7070\n",
            "Epoch 111/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8416.6064 - val_loss: 8514.8857\n",
            "Epoch 112/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8326.7021 - val_loss: 8492.1045\n",
            "Epoch 113/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8302.8975 - val_loss: 8578.4365\n",
            "Epoch 114/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8289.3213 - val_loss: 8479.1338\n",
            "Epoch 115/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8337.6543 - val_loss: 8300.3760\n",
            "Epoch 116/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8295.8887 - val_loss: 8882.8379\n",
            "Epoch 117/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 8467.0059 - val_loss: 8391.4414\n",
            "Epoch 118/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8227.2588 - val_loss: 8229.7051\n",
            "Epoch 119/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8106.2476 - val_loss: 8184.8389\n",
            "Epoch 120/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 8094.2275 - val_loss: 8420.1992\n",
            "Epoch 121/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8235.8887 - val_loss: 8586.7451\n",
            "Epoch 122/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 8159.9409 - val_loss: 8063.6763\n",
            "Epoch 123/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7950.9438 - val_loss: 7990.8862\n",
            "Epoch 124/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7867.8550 - val_loss: 8030.6631\n",
            "Epoch 125/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7849.4399 - val_loss: 7925.3037\n",
            "Epoch 126/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7766.1885 - val_loss: 7916.6338\n",
            "Epoch 127/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7733.6680 - val_loss: 7933.6738\n",
            "Epoch 128/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7736.4268 - val_loss: 8085.2212\n",
            "Epoch 129/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7699.7544 - val_loss: 8126.2065\n",
            "Epoch 130/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 7883.8799 - val_loss: 8236.0195\n",
            "Epoch 131/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7717.2402 - val_loss: 7993.8374\n",
            "Epoch 132/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7801.6519 - val_loss: 7867.9399\n",
            "Epoch 133/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7844.3418 - val_loss: 7715.6470\n",
            "Epoch 134/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7948.2163 - val_loss: 7839.4209\n",
            "Epoch 135/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7743.6929 - val_loss: 7633.4224\n",
            "Epoch 136/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7627.1851 - val_loss: 7691.9961\n",
            "Epoch 137/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7588.2681 - val_loss: 7879.1108\n",
            "Epoch 138/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7727.8906 - val_loss: 8005.0479\n",
            "Epoch 139/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7623.5508 - val_loss: 7524.3955\n",
            "Epoch 140/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7497.4937 - val_loss: 7402.2646\n",
            "Epoch 141/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7512.6313 - val_loss: 7613.3394\n",
            "Epoch 142/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7575.7280 - val_loss: 7765.6597\n",
            "Epoch 143/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7568.6392 - val_loss: 8221.9395\n",
            "Epoch 144/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 7675.6904 - val_loss: 7724.5996\n",
            "Epoch 145/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7481.8555 - val_loss: 7524.8999\n",
            "Epoch 146/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7390.8770 - val_loss: 7308.5874\n",
            "Epoch 147/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7230.0884 - val_loss: 7266.4868\n",
            "Epoch 148/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7383.9351 - val_loss: 7429.7397\n",
            "Epoch 149/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7222.8770 - val_loss: 7288.1685\n",
            "Epoch 150/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7242.8433 - val_loss: 7262.9917\n",
            "Epoch 151/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 7143.8091 - val_loss: 7120.1636\n",
            "Epoch 152/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7162.6367 - val_loss: 7138.6323\n",
            "Epoch 153/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7139.2983 - val_loss: 7370.2686\n",
            "Epoch 154/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7133.3398 - val_loss: 7379.1938\n",
            "Epoch 155/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7246.5781 - val_loss: 7535.7715\n",
            "Epoch 156/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7150.8970 - val_loss: 7204.3408\n",
            "Epoch 157/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7010.9766 - val_loss: 7596.8887\n",
            "Epoch 158/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 7237.8110 - val_loss: 7004.6509\n",
            "Epoch 159/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6898.1821 - val_loss: 7202.0928\n",
            "Epoch 160/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6963.5854 - val_loss: 6941.4946\n",
            "Epoch 161/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6950.5698 - val_loss: 6914.3564\n",
            "Epoch 162/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6916.1787 - val_loss: 7111.9136\n",
            "Epoch 163/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6956.4067 - val_loss: 6966.1035\n",
            "Epoch 164/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6901.1973 - val_loss: 7024.5591\n",
            "Epoch 165/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6767.2803 - val_loss: 6842.3843\n",
            "Epoch 166/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6824.5479 - val_loss: 6834.1343\n",
            "Epoch 167/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6810.2642 - val_loss: 6764.6353\n",
            "Epoch 168/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6749.5464 - val_loss: 6756.0957\n",
            "Epoch 169/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6722.3877 - val_loss: 6775.6250\n",
            "Epoch 170/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6729.2827 - val_loss: 6744.9429\n",
            "Epoch 171/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6703.9336 - val_loss: 6787.6455\n",
            "Epoch 172/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6672.2715 - val_loss: 6754.1719\n",
            "Epoch 173/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6721.8110 - val_loss: 6671.3013\n",
            "Epoch 174/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6633.8711 - val_loss: 6716.3159\n",
            "Epoch 175/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6639.7837 - val_loss: 6622.4565\n",
            "Epoch 176/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6575.3862 - val_loss: 6610.8916\n",
            "Epoch 177/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6549.5034 - val_loss: 6659.9028\n",
            "Epoch 178/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6573.4902 - val_loss: 6594.7861\n",
            "Epoch 179/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6520.2300 - val_loss: 6545.0059\n",
            "Epoch 180/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6536.8442 - val_loss: 6776.1514\n",
            "Epoch 181/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6517.2266 - val_loss: 6597.0864\n",
            "Epoch 182/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6531.2676 - val_loss: 6530.3076\n",
            "Epoch 183/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6468.7451 - val_loss: 6553.0161\n",
            "Epoch 184/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6447.0361 - val_loss: 6483.2603\n",
            "Epoch 185/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 6431.3936 - val_loss: 6680.9624\n",
            "Epoch 186/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6538.0762 - val_loss: 6480.0278\n",
            "Epoch 187/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6441.6587 - val_loss: 6614.6167\n",
            "Epoch 188/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6480.2021 - val_loss: 6735.8535\n",
            "Epoch 189/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6491.4727 - val_loss: 6429.9858\n",
            "Epoch 190/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6317.1064 - val_loss: 6534.3174\n",
            "Epoch 191/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6380.4634 - val_loss: 6393.2666\n",
            "Epoch 192/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6271.6631 - val_loss: 6437.1260\n",
            "Epoch 193/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6303.9951 - val_loss: 6389.7725\n",
            "Epoch 194/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 6281.6987 - val_loss: 6344.0293\n",
            "Epoch 195/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 6233.7676 - val_loss: 6339.1597\n",
            "Epoch 196/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6334.3608 - val_loss: 6375.3623\n",
            "Epoch 197/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6339.5981 - val_loss: 6342.7202\n",
            "Epoch 198/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6304.2568 - val_loss: 6321.3794\n",
            "Epoch 199/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6299.4316 - val_loss: 6461.0098\n",
            "Epoch 200/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6426.0151 - val_loss: 7010.4966\n",
            "Epoch 201/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6569.2988 - val_loss: 6897.8643\n",
            "Epoch 202/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6616.7793 - val_loss: 6598.2451\n",
            "Epoch 203/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6376.1055 - val_loss: 6428.3403\n",
            "Epoch 204/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6333.7759 - val_loss: 6300.2944\n",
            "Epoch 205/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6241.3589 - val_loss: 6329.1289\n",
            "Epoch 206/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 6165.0420 - val_loss: 6223.0664\n",
            "Epoch 207/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6102.9189 - val_loss: 6307.0298\n",
            "Epoch 208/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6036.2778 - val_loss: 6288.6353\n",
            "Epoch 209/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6171.5283 - val_loss: 6404.5098\n",
            "Epoch 210/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6102.9976 - val_loss: 6162.0142\n",
            "Epoch 211/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6060.4424 - val_loss: 6201.4019\n",
            "Epoch 212/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6008.0244 - val_loss: 6107.7339\n",
            "Epoch 213/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5970.7856 - val_loss: 6123.2280\n",
            "Epoch 214/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6003.9106 - val_loss: 6233.0425\n",
            "Epoch 215/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5953.2349 - val_loss: 6134.1445\n",
            "Epoch 216/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5968.6685 - val_loss: 6389.3232\n",
            "Epoch 217/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6072.0386 - val_loss: 6143.1079\n",
            "Epoch 218/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5963.0859 - val_loss: 6104.9370\n",
            "Epoch 219/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5915.5098 - val_loss: 6083.3462\n",
            "Epoch 220/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5964.2080 - val_loss: 6055.5835\n",
            "Epoch 221/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5882.9702 - val_loss: 6299.4951\n",
            "Epoch 222/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5985.3164 - val_loss: 6227.8452\n",
            "Epoch 223/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5974.6001 - val_loss: 6422.0718\n",
            "Epoch 224/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5971.5454 - val_loss: 6050.4580\n",
            "Epoch 225/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5998.5762 - val_loss: 6019.3604\n",
            "Epoch 226/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6151.8433 - val_loss: 6482.9355\n",
            "Epoch 227/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 6175.2773 - val_loss: 6228.9648\n",
            "Epoch 228/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5926.1191 - val_loss: 6640.1611\n",
            "Epoch 229/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5981.1191 - val_loss: 6222.3359\n",
            "Epoch 230/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5983.3086 - val_loss: 6135.3735\n",
            "Epoch 231/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5855.5327 - val_loss: 5998.9429\n",
            "Epoch 232/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5937.7261 - val_loss: 6025.9487\n",
            "Epoch 233/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5892.0850 - val_loss: 6024.3721\n",
            "Epoch 234/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5824.9834 - val_loss: 5937.4780\n",
            "Epoch 235/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5770.9224 - val_loss: 6072.4590\n",
            "Epoch 236/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5756.8872 - val_loss: 6079.3037\n",
            "Epoch 237/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5695.6113 - val_loss: 5867.8013\n",
            "Epoch 238/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5671.7705 - val_loss: 6029.1338\n",
            "Epoch 239/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5675.0059 - val_loss: 5845.1689\n",
            "Epoch 240/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5653.8667 - val_loss: 5833.1304\n",
            "Epoch 241/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5627.0405 - val_loss: 5840.7104\n",
            "Epoch 242/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5585.0508 - val_loss: 5826.3325\n",
            "Epoch 243/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 5603.5898 - val_loss: 5812.9868\n",
            "Epoch 244/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5584.9707 - val_loss: 5839.0049\n",
            "Epoch 245/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5557.5127 - val_loss: 5795.9824\n",
            "Epoch 246/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5541.3701 - val_loss: 5789.6694\n",
            "Epoch 247/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5545.9917 - val_loss: 5795.7705\n",
            "Epoch 248/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5527.0933 - val_loss: 5777.9331\n",
            "Epoch 249/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5502.6846 - val_loss: 5850.6533\n",
            "Epoch 250/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5583.7363 - val_loss: 5796.2578\n",
            "Epoch 251/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5498.5059 - val_loss: 5768.6548\n",
            "Epoch 252/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5516.9834 - val_loss: 5825.3979\n",
            "Epoch 253/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5527.4990 - val_loss: 5877.3931\n",
            "Epoch 254/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5625.0728 - val_loss: 5823.6650\n",
            "Epoch 255/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5530.5884 - val_loss: 5772.3071\n",
            "Epoch 256/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5536.6577 - val_loss: 5926.9683\n",
            "Epoch 257/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5493.9248 - val_loss: 5779.8208\n",
            "Epoch 258/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5556.7754 - val_loss: 5962.3179\n",
            "Epoch 259/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5618.3716 - val_loss: 5769.5654\n",
            "Epoch 260/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5544.5718 - val_loss: 5784.8843\n",
            "Epoch 261/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5578.4937 - val_loss: 5807.7549\n",
            "Epoch 262/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5412.3828 - val_loss: 5712.2256\n",
            "Epoch 263/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5377.8423 - val_loss: 5702.2427\n",
            "Epoch 264/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5384.3569 - val_loss: 5709.5010\n",
            "Epoch 265/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5340.8657 - val_loss: 5665.3726\n",
            "Epoch 266/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5324.3892 - val_loss: 5661.6646\n",
            "Epoch 267/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5341.6318 - val_loss: 5717.2124\n",
            "Epoch 268/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5435.2207 - val_loss: 5728.5703\n",
            "Epoch 269/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5350.9941 - val_loss: 5664.1499\n",
            "Epoch 270/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5334.6343 - val_loss: 5671.2109\n",
            "Epoch 271/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5354.0542 - val_loss: 5675.9473\n",
            "Epoch 272/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5277.0205 - val_loss: 5632.3726\n",
            "Epoch 273/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5262.5513 - val_loss: 5706.9341\n",
            "Epoch 274/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5309.7051 - val_loss: 5813.2598\n",
            "Epoch 275/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5298.2227 - val_loss: 5749.6108\n",
            "Epoch 276/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5319.0361 - val_loss: 5778.7109\n",
            "Epoch 277/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5251.2158 - val_loss: 5634.3423\n",
            "Epoch 278/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5238.3828 - val_loss: 5684.6743\n",
            "Epoch 279/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5304.0825 - val_loss: 5623.2744\n",
            "Epoch 280/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5240.3740 - val_loss: 5597.1670\n",
            "Epoch 281/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5226.5894 - val_loss: 5589.8545\n",
            "Epoch 282/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5247.1943 - val_loss: 5558.4780\n",
            "Epoch 283/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5155.6084 - val_loss: 5680.3623\n",
            "Epoch 284/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5186.3130 - val_loss: 5563.7061\n",
            "Epoch 285/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5170.7036 - val_loss: 5565.1279\n",
            "Epoch 286/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5156.9165 - val_loss: 5579.7266\n",
            "Epoch 287/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5146.0342 - val_loss: 5573.3462\n",
            "Epoch 288/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5238.4639 - val_loss: 5562.8682\n",
            "Epoch 289/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5169.8945 - val_loss: 5639.1313\n",
            "Epoch 290/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5105.7368 - val_loss: 5537.0767\n",
            "Epoch 291/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5108.3521 - val_loss: 5520.3599\n",
            "Epoch 292/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5130.4614 - val_loss: 5525.2305\n",
            "Epoch 293/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5112.7686 - val_loss: 5517.8340\n",
            "Epoch 294/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5177.9053 - val_loss: 5728.1509\n",
            "Epoch 295/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5159.0190 - val_loss: 5526.2075\n",
            "Epoch 296/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5133.1069 - val_loss: 5524.4155\n",
            "Epoch 297/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5081.2236 - val_loss: 5617.1084\n",
            "Epoch 298/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5217.0435 - val_loss: 5570.9307\n",
            "Epoch 299/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5286.8018 - val_loss: 5533.7939\n",
            "Epoch 300/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5103.1606 - val_loss: 5505.9648\n",
            "Epoch 301/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5105.0806 - val_loss: 5843.4526\n",
            "Epoch 302/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5097.2739 - val_loss: 5771.1572\n",
            "Epoch 303/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5143.4438 - val_loss: 6088.4175\n",
            "Epoch 304/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5211.2686 - val_loss: 5582.0605\n",
            "Epoch 305/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5147.2959 - val_loss: 5495.5811\n",
            "Epoch 306/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5041.2617 - val_loss: 5739.5352\n",
            "Epoch 307/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5088.4116 - val_loss: 5542.5044\n",
            "Epoch 308/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5033.9087 - val_loss: 5683.4243\n",
            "Epoch 309/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5032.6846 - val_loss: 5592.4580\n",
            "Epoch 310/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5007.5625 - val_loss: 5641.2451\n",
            "Epoch 311/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4992.7529 - val_loss: 5755.3877\n",
            "Epoch 312/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5025.1553 - val_loss: 5731.1011\n",
            "Epoch 313/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5026.1538 - val_loss: 5892.6885\n",
            "Epoch 314/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 5014.2739 - val_loss: 5705.2534\n",
            "Epoch 315/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5054.7578 - val_loss: 5563.4712\n",
            "Epoch 316/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4948.8867 - val_loss: 5461.6157\n",
            "Epoch 317/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4990.4585 - val_loss: 5513.8989\n",
            "Epoch 318/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5002.5723 - val_loss: 5640.6104\n",
            "Epoch 319/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4934.3047 - val_loss: 5465.6851\n",
            "Epoch 320/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4928.9419 - val_loss: 5460.6406\n",
            "Epoch 321/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4837.4146 - val_loss: 5449.4077\n",
            "Epoch 322/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4830.9653 - val_loss: 5481.8599\n",
            "Epoch 323/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4821.3867 - val_loss: 5431.2505\n",
            "Epoch 324/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4897.0078 - val_loss: 5475.9414\n",
            "Epoch 325/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4921.8159 - val_loss: 5597.2886\n",
            "Epoch 326/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4868.4521 - val_loss: 5600.0879\n",
            "Epoch 327/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4944.5674 - val_loss: 5857.8257\n",
            "Epoch 328/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4863.0776 - val_loss: 5593.5039\n",
            "Epoch 329/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4993.7183 - val_loss: 5474.7329\n",
            "Epoch 330/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4953.7368 - val_loss: 5463.4946\n",
            "Epoch 331/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4962.4282 - val_loss: 5505.4585\n",
            "Epoch 332/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4964.0981 - val_loss: 6445.5913\n",
            "Epoch 333/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5144.3535 - val_loss: 5823.1245\n",
            "Epoch 334/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 5309.3667 - val_loss: 5520.0522\n",
            "Epoch 335/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 4937.1191 - val_loss: 5428.5981\n",
            "Epoch 336/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4884.5068 - val_loss: 5438.7402\n",
            "Epoch 337/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4823.3237 - val_loss: 5499.6470\n",
            "Epoch 338/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4808.5366 - val_loss: 5471.5366\n",
            "Epoch 339/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4777.6719 - val_loss: 5687.9761\n",
            "Epoch 340/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4885.0728 - val_loss: 5396.2427\n",
            "Epoch 341/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 4734.1143 - val_loss: 5401.6436\n",
            "Epoch 342/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4741.9150 - val_loss: 5412.2725\n",
            "Epoch 343/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4703.3882 - val_loss: 5379.4980\n",
            "Epoch 344/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4656.3994 - val_loss: 5351.3647\n",
            "Epoch 345/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4662.3530 - val_loss: 5458.3901\n",
            "Epoch 346/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4693.1328 - val_loss: 5378.5986\n",
            "Epoch 347/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4699.1021 - val_loss: 5380.8804\n",
            "Epoch 348/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4650.7163 - val_loss: 5503.5054\n",
            "Epoch 349/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4665.9209 - val_loss: 5414.9072\n",
            "Epoch 350/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4635.6626 - val_loss: 5416.7861\n",
            "Epoch 351/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4625.7588 - val_loss: 5425.3911\n",
            "Epoch 352/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4639.5732 - val_loss: 5580.1011\n",
            "Epoch 353/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4652.6025 - val_loss: 5482.3232\n",
            "Epoch 354/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4678.3838 - val_loss: 5534.6152\n",
            "Epoch 355/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4702.3008 - val_loss: 5394.7300\n",
            "Epoch 356/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4608.6572 - val_loss: 5332.6694\n",
            "Epoch 357/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4606.2803 - val_loss: 5363.1123\n",
            "Epoch 358/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4600.9556 - val_loss: 5362.8730\n",
            "Epoch 359/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4569.8711 - val_loss: 5300.8032\n",
            "Epoch 360/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4568.7944 - val_loss: 5347.8560\n",
            "Epoch 361/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 4539.2480 - val_loss: 5323.2676\n",
            "Epoch 362/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4537.8696 - val_loss: 5347.7759\n",
            "Epoch 363/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4542.7432 - val_loss: 5355.6562\n",
            "Epoch 364/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4595.0312 - val_loss: 5338.2920\n",
            "Epoch 365/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4512.5845 - val_loss: 5277.7539\n",
            "Epoch 366/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4509.9565 - val_loss: 5303.5024\n",
            "Epoch 367/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4516.3872 - val_loss: 5513.3525\n",
            "Epoch 368/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4625.6436 - val_loss: 5363.7520\n",
            "Epoch 369/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4604.7539 - val_loss: 5323.6865\n",
            "Epoch 370/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4494.3682 - val_loss: 5308.8267\n",
            "Epoch 371/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4503.2075 - val_loss: 5325.9541\n",
            "Epoch 372/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4531.4370 - val_loss: 5561.4238\n",
            "Epoch 373/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4592.2827 - val_loss: 5347.9907\n",
            "Epoch 374/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4507.0059 - val_loss: 5516.0215\n",
            "Epoch 375/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4584.2363 - val_loss: 5318.4502\n",
            "Epoch 376/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4484.6416 - val_loss: 5348.5103\n",
            "Epoch 377/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4627.9409 - val_loss: 5326.4644\n",
            "Epoch 378/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4445.7051 - val_loss: 5274.3013\n",
            "Epoch 379/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4469.3218 - val_loss: 5411.9893\n",
            "Epoch 380/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4453.1836 - val_loss: 5251.9292\n",
            "Epoch 381/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4497.9292 - val_loss: 5268.1704\n",
            "Epoch 382/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4482.7710 - val_loss: 5753.0913\n",
            "Epoch 383/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4575.9585 - val_loss: 5329.8398\n",
            "Epoch 384/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4622.7642 - val_loss: 5293.2402\n",
            "Epoch 385/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4465.6357 - val_loss: 5345.2939\n",
            "Epoch 386/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4541.4282 - val_loss: 5325.3545\n",
            "Epoch 387/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4471.8525 - val_loss: 5875.6831\n",
            "Epoch 388/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4590.9497 - val_loss: 5386.7051\n",
            "Epoch 389/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4613.2466 - val_loss: 5304.8975\n",
            "Epoch 390/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4539.8247 - val_loss: 5613.3027\n",
            "Epoch 391/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4554.3267 - val_loss: 5304.7905\n",
            "Epoch 392/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4478.5557 - val_loss: 5274.6938\n",
            "Epoch 393/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4488.3730 - val_loss: 5463.1455\n",
            "Epoch 394/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4579.7188 - val_loss: 5431.6860\n",
            "Epoch 395/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4553.1890 - val_loss: 5895.9199\n",
            "Epoch 396/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4689.5938 - val_loss: 5240.6704\n",
            "Epoch 397/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4498.1851 - val_loss: 5228.3916\n",
            "Epoch 398/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4427.8306 - val_loss: 5354.3574\n",
            "Epoch 399/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4388.4038 - val_loss: 5296.5498\n",
            "Epoch 400/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4418.3442 - val_loss: 5532.9595\n",
            "Epoch 401/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4461.4536 - val_loss: 5198.2310\n",
            "Epoch 402/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4373.3115 - val_loss: 5232.6064\n",
            "Epoch 403/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4358.0088 - val_loss: 5325.8682\n",
            "Epoch 404/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4314.9146 - val_loss: 5233.1064\n",
            "Epoch 405/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4331.4644 - val_loss: 5317.3940\n",
            "Epoch 406/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4295.7759 - val_loss: 5223.5474\n",
            "Epoch 407/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4354.6587 - val_loss: 5226.4146\n",
            "Epoch 408/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 4276.6958 - val_loss: 5231.5938\n",
            "Epoch 409/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4271.1323 - val_loss: 5239.6328\n",
            "Epoch 410/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4258.8188 - val_loss: 5338.9243\n",
            "Epoch 411/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4266.0610 - val_loss: 5247.9668\n",
            "Epoch 412/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4274.8467 - val_loss: 5250.4233\n",
            "Epoch 413/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4285.1426 - val_loss: 5295.6895\n",
            "Epoch 414/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4238.3940 - val_loss: 5255.7793\n",
            "Epoch 415/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4262.6216 - val_loss: 5396.1978\n",
            "Epoch 416/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4368.2881 - val_loss: 5309.0933\n",
            "Epoch 417/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4288.6675 - val_loss: 5490.4937\n",
            "Epoch 418/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4405.0708 - val_loss: 5446.7251\n",
            "Epoch 419/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4420.9736 - val_loss: 5590.5059\n",
            "Epoch 420/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4433.8555 - val_loss: 5290.2217\n",
            "Epoch 421/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4429.9136 - val_loss: 5326.3540\n",
            "Epoch 422/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4342.1177 - val_loss: 5348.9858\n",
            "Epoch 423/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4242.1729 - val_loss: 5280.2769\n",
            "Epoch 424/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4229.7837 - val_loss: 5242.2842\n",
            "Epoch 425/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4195.2681 - val_loss: 5275.9424\n",
            "Epoch 426/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4180.3052 - val_loss: 5253.9697\n",
            "Epoch 427/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4180.2983 - val_loss: 5230.6978\n",
            "Epoch 428/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4174.4814 - val_loss: 5277.2783\n",
            "Epoch 429/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4234.8286 - val_loss: 5262.6914\n",
            "Epoch 430/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4245.6294 - val_loss: 5211.3521\n",
            "Epoch 431/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4239.2764 - val_loss: 5456.9624\n",
            "Epoch 432/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4273.7417 - val_loss: 5235.2930\n",
            "Epoch 433/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4200.9795 - val_loss: 5333.4609\n",
            "Epoch 434/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4201.7671 - val_loss: 5308.0688\n",
            "Epoch 435/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4267.9922 - val_loss: 5452.7153\n",
            "Epoch 436/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4291.9043 - val_loss: 5346.0747\n",
            "Epoch 437/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4338.9854 - val_loss: 5436.5142\n",
            "Epoch 438/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 4272.4834 - val_loss: 5224.5107\n",
            "Epoch 439/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4274.0142 - val_loss: 5270.1299\n",
            "Epoch 440/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4255.8848 - val_loss: 5361.9976\n",
            "Epoch 441/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4215.3003 - val_loss: 5246.6533\n",
            "Epoch 442/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4228.3887 - val_loss: 5328.8340\n",
            "Epoch 443/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4142.1411 - val_loss: 5261.5239\n",
            "Epoch 444/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4129.3193 - val_loss: 5259.9072\n",
            "Epoch 445/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4181.1006 - val_loss: 5610.7354\n",
            "Epoch 446/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4266.5293 - val_loss: 5252.9023\n",
            "Epoch 447/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4114.9395 - val_loss: 5342.8257\n",
            "Epoch 448/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4121.0234 - val_loss: 5374.9624\n",
            "Epoch 449/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4141.7690 - val_loss: 5237.0591\n",
            "Epoch 450/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4104.8481 - val_loss: 5257.6216\n",
            "Epoch 451/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4044.0789 - val_loss: 5202.9150\n",
            "Epoch 452/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4045.7959 - val_loss: 5218.0854\n",
            "Epoch 453/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4044.4814 - val_loss: 5195.4668\n",
            "Epoch 454/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4150.4819 - val_loss: 5276.5625\n",
            "Epoch 455/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4047.4111 - val_loss: 5220.3716\n",
            "Epoch 456/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4128.7407 - val_loss: 5245.7622\n",
            "Epoch 457/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4102.8408 - val_loss: 5248.8257\n",
            "Epoch 458/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4057.2166 - val_loss: 5196.9473\n",
            "Epoch 459/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4062.8372 - val_loss: 5343.0889\n",
            "Epoch 460/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4118.3706 - val_loss: 5205.5742\n",
            "Epoch 461/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4052.0620 - val_loss: 5221.3921\n",
            "Epoch 462/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4019.2139 - val_loss: 5253.1528\n",
            "Epoch 463/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4013.5662 - val_loss: 5284.7378\n",
            "Epoch 464/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4091.3574 - val_loss: 5325.2456\n",
            "Epoch 465/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 4119.9160 - val_loss: 5274.9795\n",
            "Epoch 466/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4039.3491 - val_loss: 5252.6841\n",
            "Epoch 467/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3988.4297 - val_loss: 5206.4990\n",
            "Epoch 468/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4049.6353 - val_loss: 5170.0122\n",
            "Epoch 469/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4132.5244 - val_loss: 5460.5225\n",
            "Epoch 470/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4110.3511 - val_loss: 5209.9653\n",
            "Epoch 471/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4154.1875 - val_loss: 5176.8042\n",
            "Epoch 472/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4130.4961 - val_loss: 5467.2769\n",
            "Epoch 473/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4076.3599 - val_loss: 5176.9575\n",
            "Epoch 474/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4012.6299 - val_loss: 5297.3208\n",
            "Epoch 475/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4028.2207 - val_loss: 5172.1392\n",
            "Epoch 476/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3970.1228 - val_loss: 5168.8350\n",
            "Epoch 477/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3963.9324 - val_loss: 5190.7578\n",
            "Epoch 478/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3932.7495 - val_loss: 5241.9502\n",
            "Epoch 479/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3929.5706 - val_loss: 5167.7378\n",
            "Epoch 480/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3894.0308 - val_loss: 5278.4502\n",
            "Epoch 481/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3930.4646 - val_loss: 5162.7388\n",
            "Epoch 482/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3911.1699 - val_loss: 5173.5493\n",
            "Epoch 483/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3913.1621 - val_loss: 5418.4932\n",
            "Epoch 484/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4009.4795 - val_loss: 5175.3843\n",
            "Epoch 485/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3900.4619 - val_loss: 5311.2529\n",
            "Epoch 486/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3925.0750 - val_loss: 5259.4414\n",
            "Epoch 487/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3897.0393 - val_loss: 5242.1895\n",
            "Epoch 488/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3902.8789 - val_loss: 5454.8442\n",
            "Epoch 489/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4126.4468 - val_loss: 5478.5669\n",
            "Epoch 490/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4253.1245 - val_loss: 5396.9863\n",
            "Epoch 491/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4038.0173 - val_loss: 5232.3354\n",
            "Epoch 492/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3994.1897 - val_loss: 5272.0669\n",
            "Epoch 493/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4174.5645 - val_loss: 5580.6597\n",
            "Epoch 494/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4082.9319 - val_loss: 5297.6226\n",
            "Epoch 495/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4167.0601 - val_loss: 5251.0234\n",
            "Epoch 496/1000\n",
            "3/3 [==============================] - ETA: 0s - loss: 4126.0024Epoch 497/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4177.3901 - val_loss: 5257.2954\n",
            "Epoch 498/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4063.7556 - val_loss: 5521.2012\n",
            "Epoch 499/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3931.5085 - val_loss: 5172.4922\n",
            "Epoch 500/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3886.1919 - val_loss: 5261.1826\n",
            "Epoch 501/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3857.6812 - val_loss: 5182.9810\n",
            "Epoch 502/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3894.2317 - val_loss: 5181.3525\n",
            "Epoch 503/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3991.5022 - val_loss: 5340.2109\n",
            "Epoch 504/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3911.5452 - val_loss: 5153.1841\n",
            "Epoch 505/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3975.8992 - val_loss: 5219.6294\n",
            "Epoch 506/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4153.1128 - val_loss: 5407.9844\n",
            "Epoch 507/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3903.5466 - val_loss: 5242.0229\n",
            "Epoch 508/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3964.3696 - val_loss: 5393.4868\n",
            "Epoch 509/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3902.2717 - val_loss: 5162.9351\n",
            "Epoch 510/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3852.3586 - val_loss: 5268.0269\n",
            "Epoch 511/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3802.4668 - val_loss: 5217.9380\n",
            "Epoch 512/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3829.2029 - val_loss: 5264.5400\n",
            "Epoch 513/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3842.0417 - val_loss: 5156.3286\n",
            "Epoch 514/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3836.0369 - val_loss: 5184.8599\n",
            "Epoch 515/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3766.3252 - val_loss: 5319.1104\n",
            "Epoch 516/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3769.5110 - val_loss: 5262.0498\n",
            "Epoch 517/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3986.3630 - val_loss: 5544.4189\n",
            "Epoch 518/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3988.1406 - val_loss: 5223.5107\n",
            "Epoch 519/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 4086.1853 - val_loss: 5209.6372\n",
            "Epoch 520/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3843.8975 - val_loss: 5115.6646\n",
            "Epoch 521/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3872.3774 - val_loss: 5096.9502\n",
            "Epoch 522/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3816.3599 - val_loss: 5327.8965\n",
            "Epoch 523/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3788.4458 - val_loss: 5159.8721\n",
            "Epoch 524/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3873.4692 - val_loss: 5363.2847\n",
            "Epoch 525/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3848.9309 - val_loss: 5129.2573\n",
            "Epoch 526/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3795.1091 - val_loss: 5118.1992\n",
            "Epoch 527/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3736.1472 - val_loss: 5140.6045\n",
            "Epoch 528/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3711.7949 - val_loss: 5138.9863\n",
            "Epoch 529/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3718.5259 - val_loss: 5130.3833\n",
            "Epoch 530/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3719.2329 - val_loss: 5135.2397\n",
            "Epoch 531/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3696.5076 - val_loss: 5136.9253\n",
            "Epoch 532/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3724.9209 - val_loss: 5254.6240\n",
            "Epoch 533/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3721.2842 - val_loss: 5116.2217\n",
            "Epoch 534/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3780.4067 - val_loss: 5246.7798\n",
            "Epoch 535/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3718.3035 - val_loss: 5104.7305\n",
            "Epoch 536/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3705.4189 - val_loss: 5126.5840\n",
            "Epoch 537/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3683.6121 - val_loss: 5244.7915\n",
            "Epoch 538/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3775.7751 - val_loss: 5100.9595\n",
            "Epoch 539/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3660.2629 - val_loss: 5336.6519\n",
            "Epoch 540/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3806.5557 - val_loss: 5133.4551\n",
            "Epoch 541/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3697.5068 - val_loss: 5129.7910\n",
            "Epoch 542/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3762.8318 - val_loss: 5299.2256\n",
            "Epoch 543/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3730.0112 - val_loss: 5114.0488\n",
            "Epoch 544/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3705.6882 - val_loss: 5167.8149\n",
            "Epoch 545/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3671.4841 - val_loss: 5132.7021\n",
            "Epoch 546/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3660.1870 - val_loss: 5091.0244\n",
            "Epoch 547/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3644.8337 - val_loss: 5199.8428\n",
            "Epoch 548/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3660.4834 - val_loss: 5094.6548\n",
            "Epoch 549/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3700.6475 - val_loss: 5330.1138\n",
            "Epoch 550/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3683.8452 - val_loss: 5104.6113\n",
            "Epoch 551/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3701.1416 - val_loss: 5195.1104\n",
            "Epoch 552/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3687.8176 - val_loss: 5097.9424\n",
            "Epoch 553/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3659.0388 - val_loss: 5081.9653\n",
            "Epoch 554/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3658.7703 - val_loss: 5218.3091\n",
            "Epoch 555/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3646.4270 - val_loss: 5101.8350\n",
            "Epoch 556/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3646.0439 - val_loss: 5368.5742\n",
            "Epoch 557/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3642.1853 - val_loss: 5069.8301\n",
            "Epoch 558/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3713.2954 - val_loss: 5094.6689\n",
            "Epoch 559/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3659.2983 - val_loss: 5161.4126\n",
            "Epoch 560/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3623.6023 - val_loss: 5056.9746\n",
            "Epoch 561/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3629.6851 - val_loss: 5160.1611\n",
            "Epoch 562/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3658.7827 - val_loss: 5263.8452\n",
            "Epoch 563/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3637.1589 - val_loss: 5147.2520\n",
            "Epoch 564/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3792.5916 - val_loss: 5448.7085\n",
            "Epoch 565/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3709.9033 - val_loss: 5280.8594\n",
            "Epoch 566/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3806.1487 - val_loss: 5518.6216\n",
            "Epoch 567/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3756.3452 - val_loss: 5067.0645\n",
            "Epoch 568/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3645.4712 - val_loss: 5170.5620\n",
            "Epoch 569/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3660.5818 - val_loss: 5166.6611\n",
            "Epoch 570/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3599.6919 - val_loss: 5116.9673\n",
            "Epoch 571/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3571.8672 - val_loss: 5130.7993\n",
            "Epoch 572/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3579.1423 - val_loss: 5152.7427\n",
            "Epoch 573/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3553.2651 - val_loss: 5071.6045\n",
            "Epoch 574/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3572.3823 - val_loss: 5148.8599\n",
            "Epoch 575/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3608.3052 - val_loss: 5181.9756\n",
            "Epoch 576/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3631.5576 - val_loss: 5179.2837\n",
            "Epoch 577/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3686.1895 - val_loss: 5415.1670\n",
            "Epoch 578/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3629.2263 - val_loss: 5095.6099\n",
            "Epoch 579/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3614.8513 - val_loss: 5133.0669\n",
            "Epoch 580/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3572.9487 - val_loss: 5165.7949\n",
            "Epoch 581/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3501.0042 - val_loss: 5105.2314\n",
            "Epoch 582/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3589.5088 - val_loss: 5118.8784\n",
            "Epoch 583/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3548.2188 - val_loss: 5175.2188\n",
            "Epoch 584/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3487.5613 - val_loss: 5060.1680\n",
            "Epoch 585/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3495.6177 - val_loss: 5121.6133\n",
            "Epoch 586/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3549.4629 - val_loss: 5169.7241\n",
            "Epoch 587/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3506.1741 - val_loss: 5058.4175\n",
            "Epoch 588/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3476.7224 - val_loss: 5196.9575\n",
            "Epoch 589/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3472.1328 - val_loss: 5107.2954\n",
            "Epoch 590/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3526.4954 - val_loss: 5195.8169\n",
            "Epoch 591/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3482.6655 - val_loss: 5071.7583\n",
            "Epoch 592/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3480.7678 - val_loss: 5064.5645\n",
            "Epoch 593/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3556.8643 - val_loss: 5146.1343\n",
            "Epoch 594/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3465.7380 - val_loss: 5066.7178\n",
            "Epoch 595/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3474.8025 - val_loss: 5056.1294\n",
            "Epoch 596/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3506.9026 - val_loss: 5122.0063\n",
            "Epoch 597/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3479.2214 - val_loss: 5099.0386\n",
            "Epoch 598/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3540.4043 - val_loss: 5357.6719\n",
            "Epoch 599/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3523.2605 - val_loss: 5048.4282\n",
            "Epoch 600/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3539.9612 - val_loss: 5312.2188\n",
            "Epoch 601/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3586.1914 - val_loss: 5062.8818\n",
            "Epoch 602/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3511.7307 - val_loss: 5091.6914\n",
            "Epoch 603/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3473.3499 - val_loss: 5177.3687\n",
            "Epoch 604/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3456.1646 - val_loss: 5123.4922\n",
            "Epoch 605/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3512.0271 - val_loss: 5084.0283\n",
            "Epoch 606/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3461.1516 - val_loss: 5223.4067\n",
            "Epoch 607/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3464.3354 - val_loss: 5132.9492\n",
            "Epoch 608/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3633.7356 - val_loss: 5299.6704\n",
            "Epoch 609/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3491.0220 - val_loss: 5152.2349\n",
            "Epoch 610/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3553.5938 - val_loss: 5241.1011\n",
            "Epoch 611/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3507.1531 - val_loss: 5086.8560\n",
            "Epoch 612/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3471.1169 - val_loss: 5095.1479\n",
            "Epoch 613/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3479.3948 - val_loss: 5241.2319\n",
            "Epoch 614/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3414.4521 - val_loss: 5053.4482\n",
            "Epoch 615/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3417.4092 - val_loss: 5082.4834\n",
            "Epoch 616/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3386.3740 - val_loss: 5100.4087\n",
            "Epoch 617/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3363.1504 - val_loss: 5030.0151\n",
            "Epoch 618/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3383.6045 - val_loss: 5275.5386\n",
            "Epoch 619/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3433.4314 - val_loss: 5031.8823\n",
            "Epoch 620/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3441.7236 - val_loss: 5134.3022\n",
            "Epoch 621/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3418.3418 - val_loss: 5134.8188\n",
            "Epoch 622/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3386.9023 - val_loss: 5050.5801\n",
            "Epoch 623/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3389.7056 - val_loss: 5336.2803\n",
            "Epoch 624/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3392.5217 - val_loss: 5102.5352\n",
            "Epoch 625/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3427.2903 - val_loss: 5151.9731\n",
            "Epoch 626/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3399.4028 - val_loss: 5079.3833\n",
            "Epoch 627/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3355.7908 - val_loss: 5056.6045\n",
            "Epoch 628/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3338.8086 - val_loss: 5329.2441\n",
            "Epoch 629/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3439.8135 - val_loss: 5142.7710\n",
            "Epoch 630/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3420.3579 - val_loss: 5074.6167\n",
            "Epoch 631/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3368.8894 - val_loss: 5158.4043\n",
            "Epoch 632/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3340.3313 - val_loss: 5043.0000\n",
            "Epoch 633/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3387.7771 - val_loss: 5112.8926\n",
            "Epoch 634/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3362.2800 - val_loss: 5114.0439\n",
            "Epoch 635/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3383.0073 - val_loss: 5001.3979\n",
            "Epoch 636/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3432.6111 - val_loss: 5377.6865\n",
            "Epoch 637/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3443.6836 - val_loss: 5275.2124\n",
            "Epoch 638/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3650.3599 - val_loss: 5553.9585\n",
            "Epoch 639/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3678.7388 - val_loss: 5069.7578\n",
            "Epoch 640/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 3513.8838 - val_loss: 5137.8477\n",
            "Epoch 641/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3506.9282 - val_loss: 5260.1592\n",
            "Epoch 642/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3470.2341 - val_loss: 5133.7788\n",
            "Epoch 643/1000\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3350.2117 - val_loss: 5092.7524\n",
            "Epoch 644/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3294.2109 - val_loss: 5039.0605\n",
            "Epoch 645/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3298.7234 - val_loss: 5120.3652\n",
            "Epoch 646/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3324.6133 - val_loss: 5098.1621\n",
            "Epoch 647/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3271.0137 - val_loss: 4992.9531\n",
            "Epoch 648/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3269.9978 - val_loss: 5201.3643\n",
            "Epoch 649/1000\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3308.3752 - val_loss: 5002.3560\n",
            "Epoch 650/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3287.7031 - val_loss: 5084.5449\n",
            "Epoch 651/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3545.8997 - val_loss: 5152.1738\n",
            "Epoch 652/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3420.3647 - val_loss: 5094.8257\n",
            "Epoch 653/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3479.8167 - val_loss: 5318.6035\n",
            "Epoch 654/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 3358.9390 - val_loss: 5081.4746\n",
            "Epoch 655/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3506.1846 - val_loss: 5290.5835\n",
            "Epoch 656/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3361.9211 - val_loss: 5039.6245\n",
            "Epoch 657/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3360.1213 - val_loss: 5059.8740\n",
            "Epoch 658/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3335.8599 - val_loss: 5140.4209\n",
            "Epoch 659/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3414.2817 - val_loss: 5118.8096\n",
            "Epoch 660/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3486.8037 - val_loss: 5413.9116\n",
            "Epoch 661/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3372.7395 - val_loss: 5032.7466\n",
            "Epoch 662/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3295.6436 - val_loss: 5140.8857\n",
            "Epoch 663/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3262.2769 - val_loss: 5029.0249\n",
            "Epoch 664/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3274.4619 - val_loss: 5079.5547\n",
            "Epoch 665/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3220.5112 - val_loss: 5099.1323\n",
            "Epoch 666/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3244.0706 - val_loss: 5083.2485\n",
            "Epoch 667/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3363.0979 - val_loss: 5284.7046\n",
            "Epoch 668/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3284.8350 - val_loss: 5076.0400\n",
            "Epoch 669/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3257.0691 - val_loss: 5015.1704\n",
            "Epoch 670/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3303.9497 - val_loss: 5097.8022\n",
            "Epoch 671/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3244.6599 - val_loss: 5000.7842\n",
            "Epoch 672/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3237.5933 - val_loss: 5068.2354\n",
            "Epoch 673/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3202.3362 - val_loss: 4973.8218\n",
            "Epoch 674/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3227.1514 - val_loss: 5151.8135\n",
            "Epoch 675/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3208.6016 - val_loss: 4997.9595\n",
            "Epoch 676/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3171.9595 - val_loss: 5080.0688\n",
            "Epoch 677/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3178.4360 - val_loss: 5043.2544\n",
            "Epoch 678/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3289.3818 - val_loss: 5079.5991\n",
            "Epoch 679/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3213.2993 - val_loss: 5238.1567\n",
            "Epoch 680/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3304.1538 - val_loss: 5039.1567\n",
            "Epoch 681/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3179.6113 - val_loss: 4992.4067\n",
            "Epoch 682/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3184.2537 - val_loss: 5051.3667\n",
            "Epoch 683/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3173.2642 - val_loss: 4979.2773\n",
            "Epoch 684/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3221.4460 - val_loss: 5250.6841\n",
            "Epoch 685/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3392.9250 - val_loss: 5212.3574\n",
            "Epoch 686/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3441.5278 - val_loss: 5182.7744\n",
            "Epoch 687/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3421.6023 - val_loss: 5057.3721\n",
            "Epoch 688/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3226.3906 - val_loss: 5040.5103\n",
            "Epoch 689/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3220.3906 - val_loss: 5090.3745\n",
            "Epoch 690/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3211.6135 - val_loss: 5020.0474\n",
            "Epoch 691/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3180.5576 - val_loss: 5143.9062\n",
            "Epoch 692/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3189.3826 - val_loss: 4982.9292\n",
            "Epoch 693/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3171.4692 - val_loss: 5321.6895\n",
            "Epoch 694/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3245.2351 - val_loss: 4975.1636\n",
            "Epoch 695/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3252.7764 - val_loss: 4980.7803\n",
            "Epoch 696/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3200.0857 - val_loss: 5043.7246\n",
            "Epoch 697/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3294.9885 - val_loss: 5303.5264\n",
            "Epoch 698/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3296.6086 - val_loss: 5259.8438\n",
            "Epoch 699/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3294.6689 - val_loss: 5421.8179\n",
            "Epoch 700/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3313.3074 - val_loss: 5210.6440\n",
            "Epoch 701/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3371.9929 - val_loss: 5426.0503\n",
            "Epoch 702/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3376.9253 - val_loss: 5030.7705\n",
            "Epoch 703/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3289.6152 - val_loss: 5130.0220\n",
            "Epoch 704/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3369.9561 - val_loss: 5168.2158\n",
            "Epoch 705/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3220.6572 - val_loss: 5051.5029\n",
            "Epoch 706/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3314.2817 - val_loss: 5245.9912\n",
            "Epoch 707/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3321.3618 - val_loss: 5176.9917\n",
            "Epoch 708/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3233.2434 - val_loss: 5264.9829\n",
            "Epoch 709/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3224.7234 - val_loss: 5166.8340\n",
            "Epoch 710/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3235.2983 - val_loss: 5176.0464\n",
            "Epoch 711/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3155.5229 - val_loss: 5163.9644\n",
            "Epoch 712/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3166.9570 - val_loss: 5174.0586\n",
            "Epoch 713/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3144.2871 - val_loss: 5161.7461\n",
            "Epoch 714/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3252.5986 - val_loss: 5325.2769\n",
            "Epoch 715/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3173.4587 - val_loss: 5124.2085\n",
            "Epoch 716/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3179.7600 - val_loss: 5233.3652\n",
            "Epoch 717/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3159.1326 - val_loss: 5168.0347\n",
            "Epoch 718/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3120.9731 - val_loss: 5329.8838\n",
            "Epoch 719/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3138.9514 - val_loss: 5202.1841\n",
            "Epoch 720/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3148.2034 - val_loss: 5352.2764\n",
            "Epoch 721/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3185.6394 - val_loss: 5265.6836\n",
            "Epoch 722/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3185.0625 - val_loss: 5305.9746\n",
            "Epoch 723/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3168.5779 - val_loss: 5120.9673\n",
            "Epoch 724/1000\n",
            "3/3 [==============================] - 8s 4s/step - loss: 3139.9583 - val_loss: 5138.9531\n",
            "Epoch 725/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3213.9734 - val_loss: 5233.5532\n",
            "Epoch 726/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3148.6665 - val_loss: 5095.2480\n",
            "Epoch 727/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3192.7126 - val_loss: 5308.0850\n",
            "Epoch 728/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3157.5322 - val_loss: 5025.6260\n",
            "Epoch 729/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3140.6907 - val_loss: 5142.2036\n",
            "Epoch 730/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3093.9795 - val_loss: 5003.2036\n",
            "Epoch 731/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3089.3303 - val_loss: 5035.5132\n",
            "Epoch 732/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3123.3774 - val_loss: 5080.8369\n",
            "Epoch 733/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3080.9268 - val_loss: 4968.8472\n",
            "Epoch 734/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3049.3977 - val_loss: 5072.0303\n",
            "Epoch 735/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3118.1667 - val_loss: 5072.6543\n",
            "Epoch 736/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3303.4573 - val_loss: 5311.3604\n",
            "Epoch 737/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3151.3972 - val_loss: 5069.2529\n",
            "Epoch 738/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3167.7078 - val_loss: 5418.7769\n",
            "Epoch 739/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3164.2249 - val_loss: 5009.0303\n",
            "Epoch 740/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3099.9771 - val_loss: 5237.5654\n",
            "Epoch 741/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3062.2410 - val_loss: 5026.2559\n",
            "Epoch 742/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3043.5061 - val_loss: 5074.7744\n",
            "Epoch 743/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3013.8472 - val_loss: 4997.4688\n",
            "Epoch 744/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3020.1772 - val_loss: 5045.3848\n",
            "Epoch 745/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3035.2886 - val_loss: 5129.0229\n",
            "Epoch 746/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3053.3384 - val_loss: 5003.6035\n",
            "Epoch 747/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3040.4319 - val_loss: 5135.6499\n",
            "Epoch 748/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3060.6941 - val_loss: 4999.5811\n",
            "Epoch 749/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 3006.9194 - val_loss: 5034.0103\n",
            "Epoch 750/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2992.5645 - val_loss: 5019.6802\n",
            "Epoch 751/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2962.2083 - val_loss: 5078.3813\n",
            "Epoch 752/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2979.6560 - val_loss: 5061.8862\n",
            "Epoch 753/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2959.5747 - val_loss: 5115.6826\n",
            "Epoch 754/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2959.4094 - val_loss: 5004.3794\n",
            "Epoch 755/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3011.1853 - val_loss: 5072.9429\n",
            "Epoch 756/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2996.4312 - val_loss: 5045.9492\n",
            "Epoch 757/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2977.9495 - val_loss: 4994.1807\n",
            "Epoch 758/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2947.9790 - val_loss: 5000.2373\n",
            "Epoch 759/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2941.5947 - val_loss: 5012.4038\n",
            "Epoch 760/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2952.7422 - val_loss: 4981.0215\n",
            "Epoch 761/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2942.1245 - val_loss: 5014.0693\n",
            "Epoch 762/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2954.1611 - val_loss: 5028.0298\n",
            "Epoch 763/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2945.2117 - val_loss: 4954.4814\n",
            "Epoch 764/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2956.4863 - val_loss: 5057.6646\n",
            "Epoch 765/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2951.9048 - val_loss: 4969.2310\n",
            "Epoch 766/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2958.4077 - val_loss: 4976.1377\n",
            "Epoch 767/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2932.6719 - val_loss: 4993.7148\n",
            "Epoch 768/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2963.9338 - val_loss: 5020.5107\n",
            "Epoch 769/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2986.6323 - val_loss: 5017.6055\n",
            "Epoch 770/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2979.6812 - val_loss: 4980.9990\n",
            "Epoch 771/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2964.6052 - val_loss: 5039.3691\n",
            "Epoch 772/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2992.0203 - val_loss: 4983.4072\n",
            "Epoch 773/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2962.4624 - val_loss: 5003.4219\n",
            "Epoch 774/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2930.6833 - val_loss: 5002.5239\n",
            "Epoch 775/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2900.4497 - val_loss: 5006.1250\n",
            "Epoch 776/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2893.3350 - val_loss: 5188.3594\n",
            "Epoch 777/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2925.5627 - val_loss: 5011.6763\n",
            "Epoch 778/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2977.8362 - val_loss: 5095.1851\n",
            "Epoch 779/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2932.7705 - val_loss: 5037.0249\n",
            "Epoch 780/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2955.8545 - val_loss: 5028.3281\n",
            "Epoch 781/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2932.0430 - val_loss: 5046.8594\n",
            "Epoch 782/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2915.4868 - val_loss: 4984.8706\n",
            "Epoch 783/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2908.3066 - val_loss: 5020.2183\n",
            "Epoch 784/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2886.2654 - val_loss: 4992.5728\n",
            "Epoch 785/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2852.8818 - val_loss: 4960.5942\n",
            "Epoch 786/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2895.8459 - val_loss: 5027.5986\n",
            "Epoch 787/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2864.0540 - val_loss: 4984.1191\n",
            "Epoch 788/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2847.5942 - val_loss: 5011.2900\n",
            "Epoch 789/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2842.1360 - val_loss: 4999.4849\n",
            "Epoch 790/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2839.6357 - val_loss: 5039.5781\n",
            "Epoch 791/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2874.0754 - val_loss: 4981.8115\n",
            "Epoch 792/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2862.3843 - val_loss: 5002.3638\n",
            "Epoch 793/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2882.5894 - val_loss: 5071.4263\n",
            "Epoch 794/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2900.1719 - val_loss: 5028.6904\n",
            "Epoch 795/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2859.8091 - val_loss: 5006.4399\n",
            "Epoch 796/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2855.7358 - val_loss: 5183.5986\n",
            "Epoch 797/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2933.7854 - val_loss: 5009.5859\n",
            "Epoch 798/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2894.2876 - val_loss: 5095.1899\n",
            "Epoch 799/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2871.3491 - val_loss: 5354.8892\n",
            "Epoch 800/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3008.8030 - val_loss: 5200.6211\n",
            "Epoch 801/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2950.7947 - val_loss: 5142.6289\n",
            "Epoch 802/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2988.3530 - val_loss: 5371.0332\n",
            "Epoch 803/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2979.1467 - val_loss: 5249.2705\n",
            "Epoch 804/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2924.8384 - val_loss: 5323.3193\n",
            "Epoch 805/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2919.2913 - val_loss: 5234.0488\n",
            "Epoch 806/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2869.1763 - val_loss: 5134.5693\n",
            "Epoch 807/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2851.8767 - val_loss: 5012.4995\n",
            "Epoch 808/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2892.0535 - val_loss: 4972.7378\n",
            "Epoch 809/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3002.6404 - val_loss: 5007.1514\n",
            "Epoch 810/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2894.0232 - val_loss: 5014.4678\n",
            "Epoch 811/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2873.1511 - val_loss: 4987.2915\n",
            "Epoch 812/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2852.0735 - val_loss: 5082.9565\n",
            "Epoch 813/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2825.1462 - val_loss: 4959.4248\n",
            "Epoch 814/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2859.1985 - val_loss: 5107.5200\n",
            "Epoch 815/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2784.7983 - val_loss: 5061.0542\n",
            "Epoch 816/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2886.3660 - val_loss: 4993.3491\n",
            "Epoch 817/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2861.3091 - val_loss: 5146.1816\n",
            "Epoch 818/1000\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2827.6335 - val_loss: 4996.5337\n",
            "Epoch 819/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2901.0149 - val_loss: 5185.3262\n",
            "Epoch 820/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3215.3086 - val_loss: 5037.9170\n",
            "Epoch 821/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3005.5876 - val_loss: 5132.2861\n",
            "Epoch 822/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2949.5344 - val_loss: 5463.8330\n",
            "Epoch 823/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2953.3813 - val_loss: 5185.9248\n",
            "Epoch 824/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2882.4182 - val_loss: 5575.9097\n",
            "Epoch 825/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2942.0977 - val_loss: 5227.6260\n",
            "Epoch 826/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 3042.0562 - val_loss: 5114.9282\n",
            "Epoch 827/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2895.0977 - val_loss: 4988.7134\n",
            "Epoch 828/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2790.0925 - val_loss: 5031.5200\n",
            "Epoch 829/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2770.8005 - val_loss: 5008.4238\n",
            "Epoch 830/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2772.8591 - val_loss: 5037.5938\n",
            "Epoch 831/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2745.8337 - val_loss: 4982.3257\n",
            "Epoch 832/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2759.2378 - val_loss: 4976.1304\n",
            "Epoch 833/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2740.3669 - val_loss: 4964.6523\n",
            "Epoch 834/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2725.3770 - val_loss: 5006.8916\n",
            "Epoch 835/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2754.6682 - val_loss: 5004.6509\n",
            "Epoch 836/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2729.5037 - val_loss: 5026.2598\n",
            "Epoch 837/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2780.9980 - val_loss: 5042.1709\n",
            "Epoch 838/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2857.0181 - val_loss: 5018.7798\n",
            "Epoch 839/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2766.7629 - val_loss: 5024.3159\n",
            "Epoch 840/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2761.5540 - val_loss: 5019.1914\n",
            "Epoch 841/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2726.8586 - val_loss: 5003.3003\n",
            "Epoch 842/1000\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2730.0828 - val_loss: 5014.5532\n",
            "Epoch 843/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2731.2805 - val_loss: 4997.2690\n",
            "Epoch 844/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2772.0703 - val_loss: 4967.4497\n",
            "Epoch 845/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2818.9124 - val_loss: 5274.0933\n",
            "Epoch 846/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2906.0803 - val_loss: 4940.2100\n",
            "Epoch 847/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2817.4858 - val_loss: 4996.6895\n",
            "Epoch 848/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2867.8176 - val_loss: 5193.3955\n",
            "Epoch 849/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2734.5330 - val_loss: 4949.1768\n",
            "Epoch 850/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2752.4663 - val_loss: 5296.4438\n",
            "Epoch 851/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2787.8345 - val_loss: 4934.2773\n",
            "Epoch 852/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2795.8616 - val_loss: 5132.6519\n",
            "Epoch 853/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2935.1033 - val_loss: 5000.3228\n",
            "Epoch 854/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2842.7375 - val_loss: 5033.0308\n",
            "Epoch 855/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2862.8931 - val_loss: 5092.1450\n",
            "Epoch 856/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2795.6616 - val_loss: 4969.0571\n",
            "Epoch 857/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2745.0579 - val_loss: 4986.0151\n",
            "Epoch 858/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2821.2783 - val_loss: 5196.8716\n",
            "Epoch 859/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2816.1924 - val_loss: 5115.9429\n",
            "Epoch 860/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2874.3806 - val_loss: 5135.2578\n",
            "Epoch 861/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2764.1187 - val_loss: 4960.1763\n",
            "Epoch 862/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2715.1440 - val_loss: 5089.5762\n",
            "Epoch 863/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2715.8037 - val_loss: 4961.4917\n",
            "Epoch 864/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2708.9458 - val_loss: 5019.1826\n",
            "Epoch 865/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2786.9697 - val_loss: 4953.8916\n",
            "Epoch 866/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2826.6021 - val_loss: 5030.3013\n",
            "Epoch 867/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2736.6445 - val_loss: 4972.0054\n",
            "Epoch 868/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2706.8069 - val_loss: 4991.9092\n",
            "Epoch 869/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2751.9578 - val_loss: 4965.0542\n",
            "Epoch 870/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2744.3921 - val_loss: 5019.7427\n",
            "Epoch 871/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2784.2532 - val_loss: 4949.2876\n",
            "Epoch 872/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2952.4490 - val_loss: 5157.9014\n",
            "Epoch 873/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2877.1389 - val_loss: 4939.2656\n",
            "Epoch 874/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2875.7017 - val_loss: 4980.9648\n",
            "Epoch 875/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2868.5933 - val_loss: 5163.8286\n",
            "Epoch 876/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2761.3184 - val_loss: 4979.0181\n",
            "Epoch 877/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2814.4395 - val_loss: 5124.5806\n",
            "Epoch 878/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2756.1963 - val_loss: 4934.3384\n",
            "Epoch 879/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2788.3125 - val_loss: 5062.5093\n",
            "Epoch 880/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2785.8333 - val_loss: 5052.9497\n",
            "Epoch 881/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2779.5278 - val_loss: 5112.1953\n",
            "Epoch 882/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2725.3926 - val_loss: 5287.4321\n",
            "Epoch 883/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2726.1797 - val_loss: 5119.8862\n",
            "Epoch 884/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2732.8057 - val_loss: 5099.2939\n",
            "Epoch 885/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2711.8086 - val_loss: 5051.2231\n",
            "Epoch 886/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2721.2539 - val_loss: 5036.5513\n",
            "Epoch 887/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2730.3198 - val_loss: 4993.5278\n",
            "Epoch 888/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2702.7590 - val_loss: 5010.2695\n",
            "Epoch 889/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2693.5266 - val_loss: 4946.0913\n",
            "Epoch 890/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2638.3135 - val_loss: 5052.1812\n",
            "Epoch 891/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2615.8433 - val_loss: 4932.8354\n",
            "Epoch 892/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2625.5007 - val_loss: 4967.9297\n",
            "Epoch 893/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2635.2483 - val_loss: 5020.9946\n",
            "Epoch 894/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2665.5349 - val_loss: 5004.5957\n",
            "Epoch 895/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2621.0852 - val_loss: 5051.1826\n",
            "Epoch 896/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2608.7490 - val_loss: 5094.1226\n",
            "Epoch 897/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2622.7756 - val_loss: 5028.8394\n",
            "Epoch 898/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2633.8909 - val_loss: 5073.5293\n",
            "Epoch 899/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2627.9377 - val_loss: 5107.7788\n",
            "Epoch 900/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2636.5752 - val_loss: 5039.9526\n",
            "Epoch 901/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2594.6633 - val_loss: 5031.8555\n",
            "Epoch 902/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2592.1897 - val_loss: 4978.6270\n",
            "Epoch 903/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2599.0676 - val_loss: 4951.7183\n",
            "Epoch 904/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2642.7258 - val_loss: 5183.3628\n",
            "Epoch 905/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2693.6523 - val_loss: 5007.8882\n",
            "Epoch 906/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2679.5247 - val_loss: 5052.5352\n",
            "Epoch 907/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2611.9802 - val_loss: 4902.5000\n",
            "Epoch 908/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2620.5850 - val_loss: 5062.3545\n",
            "Epoch 909/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2580.3362 - val_loss: 5018.5425\n",
            "Epoch 910/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2599.5757 - val_loss: 5009.2783\n",
            "Epoch 911/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2616.9795 - val_loss: 5007.6357\n",
            "Epoch 912/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2543.9209 - val_loss: 4979.7329\n",
            "Epoch 913/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2532.7488 - val_loss: 5003.3696\n",
            "Epoch 914/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2540.5007 - val_loss: 5008.7559\n",
            "Epoch 915/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2596.6599 - val_loss: 5001.2329\n",
            "Epoch 916/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2540.0601 - val_loss: 4988.0278\n",
            "Epoch 917/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2516.4617 - val_loss: 5045.6860\n",
            "Epoch 918/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2529.4692 - val_loss: 4955.2681\n",
            "Epoch 919/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2536.5505 - val_loss: 4985.2603\n",
            "Epoch 920/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2598.7500 - val_loss: 5167.6753\n",
            "Epoch 921/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2586.5649 - val_loss: 4929.8477\n",
            "Epoch 922/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2585.2231 - val_loss: 5030.8418\n",
            "Epoch 923/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2534.0173 - val_loss: 4993.0693\n",
            "Epoch 924/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2566.3035 - val_loss: 4932.1201\n",
            "Epoch 925/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2546.9990 - val_loss: 5051.7676\n",
            "Epoch 926/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2534.3630 - val_loss: 4964.0269\n",
            "Epoch 927/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2635.5100 - val_loss: 4982.0161\n",
            "Epoch 928/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2579.4614 - val_loss: 4947.4858\n",
            "Epoch 929/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2526.8545 - val_loss: 4989.6060\n",
            "Epoch 930/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2551.9521 - val_loss: 4927.9507\n",
            "Epoch 931/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2533.9246 - val_loss: 4986.5771\n",
            "Epoch 932/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2568.3984 - val_loss: 5076.8887\n",
            "Epoch 933/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2589.8020 - val_loss: 4942.3452\n",
            "Epoch 934/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2539.6357 - val_loss: 5070.7349\n",
            "Epoch 935/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2637.9316 - val_loss: 4945.2812\n",
            "Epoch 936/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2642.5181 - val_loss: 5053.2905\n",
            "Epoch 937/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2872.8542 - val_loss: 5056.8350\n",
            "Epoch 938/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2704.4246 - val_loss: 5066.3330\n",
            "Epoch 939/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2597.7654 - val_loss: 5047.4165\n",
            "Epoch 940/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2664.1689 - val_loss: 5424.6719\n",
            "Epoch 941/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2658.8208 - val_loss: 4982.6528\n",
            "Epoch 942/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2571.6387 - val_loss: 5173.8452\n",
            "Epoch 943/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2627.1733 - val_loss: 5165.1914\n",
            "Epoch 944/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2602.7593 - val_loss: 5173.2012\n",
            "Epoch 945/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2648.8042 - val_loss: 5165.8184\n",
            "Epoch 946/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2514.7617 - val_loss: 5021.9282\n",
            "Epoch 947/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2579.9060 - val_loss: 5068.8730\n",
            "Epoch 948/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2615.6270 - val_loss: 5192.8257\n",
            "Epoch 949/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2621.2375 - val_loss: 4973.6045\n",
            "Epoch 950/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2556.0732 - val_loss: 5096.6895\n",
            "Epoch 951/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2568.2822 - val_loss: 5215.2012\n",
            "Epoch 952/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2514.6609 - val_loss: 4985.3926\n",
            "Epoch 953/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2553.3552 - val_loss: 5067.1416\n",
            "Epoch 954/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2524.7974 - val_loss: 4993.0464\n",
            "Epoch 955/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2489.2637 - val_loss: 4967.8862\n",
            "Epoch 956/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2475.3848 - val_loss: 5012.1045\n",
            "Epoch 957/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2457.5303 - val_loss: 5061.6099\n",
            "Epoch 958/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2595.5430 - val_loss: 4997.8086\n",
            "Epoch 959/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2504.1780 - val_loss: 5004.5737\n",
            "Epoch 960/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2457.9490 - val_loss: 4948.8052\n",
            "Epoch 961/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2462.7781 - val_loss: 5016.5059\n",
            "Epoch 962/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2444.5881 - val_loss: 4974.4839\n",
            "Epoch 963/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2466.5361 - val_loss: 5018.6377\n",
            "Epoch 964/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2474.5613 - val_loss: 5105.0830\n",
            "Epoch 965/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2602.6465 - val_loss: 5055.0552\n",
            "Epoch 966/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2562.1858 - val_loss: 5064.0938\n",
            "Epoch 967/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2490.0950 - val_loss: 4941.1279\n",
            "Epoch 968/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2499.3142 - val_loss: 5032.6880\n",
            "Epoch 969/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2511.2759 - val_loss: 5138.3096\n",
            "Epoch 970/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2459.8657 - val_loss: 5022.2446\n",
            "Epoch 971/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2436.9258 - val_loss: 5008.3843\n",
            "Epoch 972/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2504.9661 - val_loss: 5128.6494\n",
            "Epoch 973/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2501.3293 - val_loss: 5009.7876\n",
            "Epoch 974/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2465.7534 - val_loss: 5040.7300\n",
            "Epoch 975/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2422.9131 - val_loss: 4996.9189\n",
            "Epoch 976/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2419.7847 - val_loss: 5030.4346\n",
            "Epoch 977/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2412.9844 - val_loss: 4992.8813\n",
            "Epoch 978/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2460.7751 - val_loss: 5039.1255\n",
            "Epoch 979/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2442.1709 - val_loss: 5014.1348\n",
            "Epoch 980/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2428.4189 - val_loss: 5013.8457\n",
            "Epoch 981/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2419.0593 - val_loss: 5070.2119\n",
            "Epoch 982/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2394.0427 - val_loss: 4967.2256\n",
            "Epoch 983/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2417.8032 - val_loss: 5091.8901\n",
            "Epoch 984/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2460.2134 - val_loss: 5037.4082\n",
            "Epoch 985/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2404.3545 - val_loss: 5108.1802\n",
            "Epoch 986/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2410.3325 - val_loss: 5027.6514\n",
            "Epoch 987/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2408.0083 - val_loss: 5090.6094\n",
            "Epoch 988/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2392.5015 - val_loss: 5007.9575\n",
            "Epoch 989/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2367.3157 - val_loss: 5035.7568\n",
            "Epoch 990/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2419.8916 - val_loss: 5139.8110\n",
            "Epoch 991/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2415.7012 - val_loss: 5096.5723\n",
            "Epoch 992/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2456.7649 - val_loss: 5090.5103\n",
            "Epoch 993/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2382.4702 - val_loss: 5018.8164\n",
            "Epoch 994/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2394.5234 - val_loss: 5025.1841\n",
            "Epoch 995/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2439.8579 - val_loss: 5345.6123\n",
            "Epoch 996/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2568.6787 - val_loss: 5040.5181\n",
            "Epoch 997/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2417.6721 - val_loss: 4951.6064\n",
            "Epoch 998/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2424.1077 - val_loss: 5044.0767\n",
            "Epoch 999/1000\n",
            "3/3 [==============================] - 10s 4s/step - loss: 2464.8008 - val_loss: 5011.0913\n",
            "Epoch 1000/1000\n",
            "3/3 [==============================] - 9s 4s/step - loss: 2410.2051 - val_loss: 5041.7705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "2Md0v4fYbBSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  test_path = \"/content/drive/MyDrive/ds677/week9/test/\"\n",
        "  data, _, true_positions = preprocess(f\"{test_path}/file_{str(1)}.hdf5\", use_tpu=True)\n",
        "\n",
        "  # Predict using the trained model\n",
        "  test_features = self_supervised_model.predict(data)\n",
        "  predictions = supervised_model.predict(test_features)\n",
        "\n",
        "# Create CSV\n",
        "df = pd.DataFrame({\n",
        "    'id': range(0, 883),\n",
        "    'x': predictions[:, 0],\n",
        "    'y': predictions[:, 1],\n",
        "    'z': predictions[:, 2]\n",
        "})\n",
        "\n",
        "mae3 = np.mean(np.abs(predictions - true_positions))\n",
        "print(f\"Mean Absolute Error with LR = 0.0008  and VS = 0.13 ratio : {mae3}\")\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/ds677/week9/predictions3.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMsloYtTBFW8",
        "outputId": "e53dbc5b-a0d5-440f-ef78-3ce94eed9c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 2s 56ms/step\n",
            "28/28 [==============================] - 11s 149ms/step\n",
            "Mean Absolute Error with LR = 0.0008  and VS = 0.13 ratio : 305.452880859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code has been separated from the above cell for documentation purposes only."
      ],
      "metadata": {
        "id": "QcF2klaCBhA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = np.mean(np.abs(predictions - true_positions))\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/ds677/week9/predictions2.csv', index=False)"
      ],
      "metadata": {
        "id": "JTq1b4gFbBi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929d2368-2682-4bbe-a597-9d6b1342e622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 3s 69ms/step\n",
            "28/28 [==============================] - 8s 145ms/step\n",
            "Mean Absolute Error: 317.5281677246094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It improved on the previous score approved on kaggle. Moving on, I'll set validation set ratio to 0.5 and lr to 0.0008 with validation set ratio set to 0.13 for the final tuning. This has been depicted in the first cell under Testing."
      ],
      "metadata": {
        "id": "SDDXsJMy8nhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the mae for my only submission on Kaggle."
      ],
      "metadata": {
        "id": "85WUycusAkyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/ds677/week9/test/\"\n",
        "data, _, true_positions = preprocess(f\"{test_path}/file_{str(1)}.hdf5\", use_tpu=True)\n",
        "pred1 = pd.read_csv('/content/drive/MyDrive/ds677/week9/predictions.csv')\n",
        "pred1.drop(columns=['id'], inplace=True)\n",
        "pred1 = pred1.to_numpy()\n",
        "mae1 = np.mean(np.abs(pred1 - true_positions))\n"
      ],
      "metadata": {
        "id": "mhIMQeoL-GTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean Absolute Error: {mae1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiSxYF_gAhdU",
        "outputId": "e7abe441-ad6d-4e55-ad4b-892bba6f6145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 313.4657287597656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To Kaggle"
      ],
      "metadata": {
        "id": "w3ICuIKfh5nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle==1.5.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL-QhhT9eTWq",
        "outputId": "8bf7b61f-923a-40b9-88c1-2ffee80a5794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle==1.5.12\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.2.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle==1.5.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle==1.5.12) (3.10)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73026 sha256=8d2c06986fe80110a9fc62e38268b1dd97b6e2872021ee9f6a5769aaf65c9df0\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/0c/e6/79103212a102e78b8453691b905f48000219574ba7137e7207\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.6.17\n",
            "    Uninstalling kaggle-1.6.17:\n",
            "      Successfully uninstalled kaggle-1.6.17\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/drive/MyDrive/kaggle.json\n",
        "!ls -la /content/drive/MyDrive/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1MN99xgh4Tj",
        "outputId": "3817662f-06e8-4c79-eb24-d9ee10637bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 70 Nov 12 15:59 /content/drive/MyDrive/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c ds-677-deep-learning-week-9-hw-1-fall-2024 -f /content/drive/MyDrive/ds677/week9/predictions3.csv -m \"submission_5\""
      ],
      "metadata": {
        "id": "umMvoNmGehwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb74eb7f-9ec7-460d-ded2-7621bbccf639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions submit -c ds-677-deep-learning-week-9-hw-1-fall-2024 -f /content/drive/MyDrive/ds677/week9/predictions3.csv -m \"submission_6\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HES7KS4xPN58",
        "outputId": "e712ae11-4c72-487c-a8b3-2f9c7d22967e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.5.12)\n",
            "100% 29.1k/29.1k [00:00<00:00, 34.7kB/s]\n",
            "Successfully submitted to DS677 Deep Learning Week9 HW1 - Fall 2024"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ho3eUxE5Poh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}